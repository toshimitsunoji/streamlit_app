# -*- coding: utf-8 -*-
"""
Deep Work æœ€å¤§åŒ–ãƒ»é›†ä¸­æ³¢è§£æã‚¢ãƒ—ãƒª (Wave Dynamics)
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import lightgbm as lgb
from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, brier_score_loss
import scipy.signal as signal
import shap
import warnings
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import matplotlib as mpl
import matplotlib.font_manager as fm
import datetime
import math
import io

# --- Streamlit ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Deep Work Wave Dynamics", layout="wide", initial_sidebar_state="expanded")

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
font_path = Path(__file__).parent / "assets" / "fonts" / "NotoSansCJKjp-Regular.otf"
if font_path.exists():
    fm.fontManager.addfont(str(font_path))
    prop = fm.FontProperties(fname=str(font_path))
    mpl.rcParams["font.family"] = prop.get_name()

mpl.rcParams["axes.unicode_minus"] = False
warnings.filterwarnings('ignore')

# --- ã‚«ã‚¹ã‚¿ãƒ CSS (æ„æ€æ±ºå®šæ”¯æ´UIå‘ã‘) ---
st.markdown("""
<style>
    .kpi-card { background-color: #ffffff; border-radius: 12px; padding: 24px; text-align: center; box-shadow: 0 4px 12px rgba(0,0,0,0.05); margin-bottom: 20px; border: 1px solid #f0f2f6; }
    .kpi-title { font-size: 1.1rem; color: #6c757d; margin-bottom: 8px; font-weight: 600; text-transform: uppercase; letter-spacing: 0.05em; }
    .kpi-value-main { font-size: 3.5rem; color: #1e293b; font-weight: 800; line-height: 1.1; margin-bottom: 5px; }
    .kpi-value-wave { font-size: 2.5rem; color: #2563eb; font-weight: 800; line-height: 1.2; margin-bottom: 5px; }
    .kpi-unit { font-size: 1.2rem; color: #64748b; font-weight: 500; }
    .kpi-sub { font-size: 1.1rem; color: #10b981; font-weight: bold; margin-top: 10px; }
    .kpi-sub.warning { color: #f59e0b; }
    .kpi-sub.alert { color: #ef4444; }
    .chance-box { background-color: #f0fdf4; border-left: 6px solid #10b981; padding: 20px; border-radius: 8px; margin-bottom: 20px; }
    .chance-time { font-size: 1.8rem; color: #047857; font-weight: 800; }
    .sim-box { background-color: #f8fafc; padding: 16px; border-radius: 8px; border: 1px dashed #cbd5e1; height: 100%; }
</style>
""", unsafe_allow_html=True)

# --- 1. æ³¢è§£æãƒ»ç‰¹å¾´é‡æŠ½å‡ºãƒ»Deep Workç”Ÿæˆ ---
def make_wave_features(df_resampled, df_sched, freq_td):
    """
    é›†ä¸­ã‚’ã€Œæ³¢ã€ã¨ã—ã¦æ‰ãˆã€å‘¨æœŸãƒ»æŒ¯å¹…ãƒ»ä½ç›¸ã‚’ç‰¹å¾´é‡åŒ–ã™ã‚‹é©æ–°çš„ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    """
    df_feat = df_resampled.copy()
    
    # 1ï¸âƒ£ çµ±åˆé›†ä¸­å¼·åº¦ã‚¹ã‚³ã‚¢ã®æ§‹ç¯‰
    score_cols = [c for c in ['CVRR_SCORE_NEW', 'RMSSD_SCORE_NEW', 'LFHF_SCORE_NEW', 'CVRR_SCORE', 'RMSSD_SCORE'] if c in df_feat.columns]
    if score_cols:
        df_feat['focus_intensity'] = df_feat[score_cols].mean(axis=1)
    elif 'é›†ä¸­åˆ¤å®š' in df_feat.columns:
        df_feat['focus_intensity'] = df_feat['é›†ä¸­åˆ¤å®š'] * 100 # ã‚¹ã‚±ãƒ¼ãƒ«åˆã‚ã›
    else:
        df_feat['focus_intensity'] = 50.0
        
    # 2ï¸âƒ£ å¹³æ»‘åŒ– (æ³¢ã‚’è¦‹ãˆã‚‹åŒ–ãƒ»5åˆ†çª“æƒ³å®š)
    win_size_5m = max(1, int(pd.Timedelta('5T') / freq_td))
    df_feat['focus_smooth'] = df_feat['focus_intensity'].rolling(window=win_size_5m, min_periods=1).mean()
    
    # 3ï¸âƒ£ æ³¢ã®ä½ç›¸ (ç°¡æ˜“çš„ãªä¸Šæ˜‡/ä¸‹é™åˆ¤å®š)
    df_feat['focus_diff'] = df_feat['focus_smooth'].diff()
    df_feat['phase_num'] = np.where(df_feat['focus_diff'] > 0, 1, np.where(df_feat['focus_diff'] < 0, -1, 0))
    df_feat['phase_str'] = np.where(df_feat['phase_num'] > 0, 'ä¸Šæ˜‡å±€é¢ â†—', np.where(df_feat['phase_num'] < 0, 'ä¸‹é™å±€é¢ â†˜', 'åœæ»'))
    
    # 4ï¸âƒ£ æ³¢ã®ç‰¹å¾´æŠ½å‡º (ãƒ”ãƒ¼ã‚¯ã¨è°·ã®æ¤œå‡º)
    dist_steps = max(1, int(pd.Timedelta('15T') / freq_td)) # æœ€ä½15åˆ†é–“éš”ã®æ³¢ã‚’æƒ³å®š
    prominence = df_feat['focus_smooth'].std() * 0.2
    if pd.isna(prominence) or prominence == 0: prominence = 0.1
    
    fs_arr = df_feat['focus_smooth'].fillna(0).values
    peaks, _ = signal.find_peaks(fs_arr, distance=dist_steps, prominence=prominence)
    valleys, _ = signal.find_peaks(-fs_arr, distance=dist_steps, prominence=prominence)
    
    df_feat['is_peak'] = 0
    if len(peaks) > 0: df_feat.iloc[peaks, df_feat.columns.get_loc('is_peak')] = 1
    df_feat['is_valley'] = 0
    if len(valleys) > 0: df_feat.iloc[valleys, df_feat.columns.get_loc('is_valley')] = 1
    
    # ç›´è¿‘ã®æ³¢ã®çŠ¶æ…‹ã‚’ä¼æ’­ (ffill)
    df_feat['last_peak_val'] = df_feat['focus_smooth'].where(df_feat['is_peak'] == 1).ffill()
    df_feat['last_valley_val'] = df_feat['focus_smooth'].where(df_feat['is_valley'] == 1).ffill()
    
    idx_series = pd.Series(df_feat.index, index=df_feat.index)
    df_feat['last_peak_time'] = idx_series.where(df_feat['is_peak'] == 1).ffill()
    
    # æ³¢ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡
    df_feat['wave_amplitude'] = (df_feat['last_peak_val'] - df_feat['last_valley_val']).fillna(0) # æŒ¯å¹…
    
    df_feat['prev_peak_time'] = df_feat['last_peak_time'].where(df_feat['is_peak']==1).shift(1).ffill()
    df_feat['wave_period_min'] = (df_feat['last_peak_time'] - df_feat['prev_peak_time']).dt.total_seconds() / 60 # å‘¨æœŸ
    df_feat['wave_period_min'] = df_feat['wave_period_min'].fillna(0)
    
    # 5ï¸âƒ£ äºˆæ¸¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å®šç¾© (ä¸Šä½30%ã®é«˜é›†ä¸­æ³¢ã«å…¥ã£ã¦ã„ã‚‹ã‹)
    q70 = df_feat['focus_smooth'].quantile(0.70)
    if pd.isna(q70): q70 = 50.0
    df_feat['is_high_focus_wave'] = (df_feat['focus_smooth'] >= q70).astype(int)
    
    # --- ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«çµ±åˆã¨ Deep Work ãƒ•ãƒ©ã‚°ã®ç”Ÿæˆ ---
    df_feat['has_schedule'] = 0
    df_feat['is_meeting'] = 0
    if df_sched is not None and not df_sched.empty:
        meeting_keywords = ['ä¼šè­°', 'æ‰“åˆã›', 'MTG', 'é¢è«‡', 'å•†è«‡']
        for _, row in df_sched.iterrows():
            mask = (df_feat.index < row['end_dt']) & ((df_feat.index + freq_td) > row['start_dt'])
            df_feat.loc[mask, 'has_schedule'] = 1
            if any(kw in str(row.get('ä»¶å', '')) for kw in meeting_keywords):
                df_feat.loc[mask, 'is_meeting'] = 1
                
    win_steps_2h = max(1, int(pd.Timedelta('2H') / freq_td))
    df_feat['schedule_density_2h'] = df_feat['has_schedule'].rolling(win_steps_2h, min_periods=1).mean().shift(1).fillna(0)
    
    # Deep Work = äºˆå®šãªã— ã‹ã¤ é«˜é›†ä¸­æ³¢
    df_feat['deep_work'] = ((df_feat['has_schedule'] == 0) & (df_feat['is_high_focus_wave'] == 1)).astype(int)
    
    # ãƒ–ãƒ­ãƒƒã‚¯è§£æ
    dw_series = df_feat['deep_work']
    df_feat['dw_block_id'] = (dw_series != dw_series.shift()).cumsum()
    df_feat['dw_block_id'] = df_feat['dw_block_id'].where(dw_series == 1, np.nan)
    
    df_feat['hour'] = df_feat.index.hour
    df_feat['dayofweek'] = df_feat.index.dayofweek
    
    return df_feat, q70

def compute_personal_metrics(df_feat, freq_td, current_time):
    """
    å€‹äººç‰¹æ€§ã¨æ³¢ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç®—å‡º
    """
    metrics = {}
    mins_per_step = freq_td.total_seconds() / 60
    df_feat['date'] = df_feat.index.date
    
    # Deep WorkåŸºç¤æŒ‡æ¨™
    block_lengths = df_feat.groupby('dw_block_id').size() * mins_per_step
    metrics['avg_dw_duration'] = block_lengths.mean() if not block_lengths.empty else 0
    metrics['dw_loss_minutes_total'] = block_lengths[block_lengths < 30].sum() if not block_lengths.empty else 0
    
    # æ³¢ã®ç‰¹æ€§æŒ‡æ¨™
    valid_periods = df_feat['wave_period_min'][df_feat['wave_period_min'] > 0]
    metrics['avg_wave_period'] = valid_periods.median() if not valid_periods.empty else 18.0
    metrics['avg_wave_amplitude'] = df_feat['wave_amplitude'][df_feat['wave_amplitude'] > 0].mean()
    if pd.isna(metrics['avg_wave_amplitude']): metrics['avg_wave_amplitude'] = 10.0
    
    # å…¨æœŸé–“ã®Deep WorkæˆåŠŸç‡ (dw_rate)
    total_blank_steps = (df_feat['has_schedule'] == 0).sum()
    total_dw_steps = df_feat['deep_work'].sum()
    metrics['dw_rate'] = (total_dw_steps / total_blank_steps * 100) if total_blank_steps > 0 else 0
    
    # ç›®æ¨™ç®—å‡º
    past_28_days = current_time.date() - pd.Timedelta(days=28)
    df_past = df_feat[(df_feat['date'] >= past_28_days) & (df_feat['date'] < current_time.date())]
    df_past_weekday = df_past[df_past['dayofweek'] < 5]
    
    if not df_past_weekday.empty:
        past_daily_dw = df_past_weekday.groupby('date')['deep_work'].sum() * mins_per_step
        target_raw = past_daily_dw.mean() * 1.10
        metrics['target_dw_mins'] = int(round(target_raw / 5.0) * 5)
    else:
        metrics['target_dw_mins'] = 120
    if metrics['target_dw_mins'] == 0: metrics['target_dw_mins'] = 60
    
    # å½“æ—¥ã®é€²æ—
    today_data = df_feat[df_feat['date'] == current_time.date()]
    today_blank_steps = (today_data['has_schedule'] == 0).sum()
    today_dw_steps = today_data['deep_work'].sum()
    metrics['today_dw_mins'] = today_dw_steps * mins_per_step
    metrics['today_dw_rate'] = (today_dw_steps / today_blank_steps * 100) if today_blank_steps > 0 else 0
    
    today_blocks = today_data.groupby('dw_block_id').size() * mins_per_step
    metrics['today_dw_loss'] = today_blocks[today_blocks < 30].sum() if not today_blocks.empty else 0
    
    return metrics

# --- 2. çŠ¶æ…‹é·ç§»äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« (æ³¢ã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã«åŸºã¥ãåˆ†é¡) ---
def train_predict_classifier(df_feat, ahead_steps):
    """
    æ³¢ç‰¹å¾´é‡ã‚’ç”¨ã„ã¦æ•°ååˆ†å…ˆã®ã€Œé«˜é›†ä¸­æ³¢ã«å…¥ã£ã¦ã„ã‚‹ã‹ã€ã‚’äºˆæ¸¬ã™ã‚‹åˆ†é¡å™¨
    """
    df_feat['target_class'] = df_feat['is_high_focus_wave'].shift(-ahead_steps)

    # äºˆæ¸¬ã«ç”¨ã„ã‚‹ç‰¹å¾´é‡ã‚»ãƒƒãƒˆï¼ˆæ³¢ãƒ»é·ç§»ãƒ»ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼‰
    feature_cols = [
        'hour', 'dayofweek', 
        'wave_amplitude', 'wave_period_min', 'phase_num',  # æ³¢ãƒ™ãƒ¼ã‚¹
        'schedule_density_2h'                              # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹
    ]
    # è¿½åŠ å¯èƒ½ãªç‰¹å¾´é‡ãŒã‚ã‚Œã°è¿½åŠ 
    for col in ['1åˆ†é–“æ­©æ•°', 'SkinTemp']:
        if col in df_feat.columns: feature_cols.append(col)
    
    df_model = df_feat.dropna(subset=['target_class'] + feature_cols).copy()
    if len(df_model) < 50:
        return None, None, {}, df_feat
        
    split_idx = int(len(df_model) * 0.8)
    train_df = df_model.iloc[:split_idx]
    test_df = df_model.iloc[split_idx:]
    
    X_train, y_train = train_df[feature_cols], train_df['target_class']
    X_test, y_test = test_df[feature_cols], test_df['target_class']
    
    if y_train.nunique() <= 1:
        return None, None, {}, df_feat
        
    model = lgb.LGBMClassifier(objective='binary', n_estimators=100, learning_rate=0.05, random_state=42, verbose=-1)
    model.fit(X_train, y_train)
    
    # è©•ä¾¡æŒ‡æ¨™ç®—å‡º
    eval_metrics = {}
    if y_test.nunique() > 1:
        preds_proba = model.predict_proba(X_test)[:, 1]
        preds_bin = (preds_proba >= 0.5).astype(int)
        eval_metrics['ROC-AUC'] = roc_auc_score(y_test, preds_proba)
        eval_metrics['PR-AUC'] = average_precision_score(y_test, preds_proba)
        eval_metrics['F1 Score'] = f1_score(y_test, preds_bin)
        eval_metrics['Brier Score'] = brier_score_loss(y_test, preds_proba)
    
    return model, feature_cols, eval_metrics, df_model

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼UI ---
with st.sidebar:
    st.header("âš™ï¸ ãƒ‡ãƒ¼ã‚¿å…¥åŠ›")
    file_ts = st.file_uploader("1. ç”Ÿä½“ãƒ‡ãƒ¼ã‚¿ (CSV)", type=['csv'])
    file_sched = st.file_uploader("2. äºˆå®šè¡¨ãƒ‡ãƒ¼ã‚¿ (CSV) â€»ä»»æ„", type=['csv'])
    
    with st.expander("ğŸ›  æ³¢è§£æãƒ»è©³ç´°è¨­å®š (ç®¡ç†è€…ç”¨)"):
        # æ³¢è§£æã‚’ç²¾å¯†ã«ã™ã‚‹ãŸã‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç´°ã‹ã„ç²’åº¦ã‚’æ¨å¥¨
        RESAMPLE_FREQ = st.selectbox("åˆ†æå˜ä½ (æ³¢è§£åƒåº¦)", ['1T', '5T', '10T', '30T'], index=1)
        PREDICT_AHEAD_MINS = st.selectbox("äºˆæ¸¬å…ˆ (åˆ†)", [30, 60], index=0)
        TARGET_DATETIME_STR = st.text_input("äºˆæ¸¬åŸºæº–æ—¥æ™‚ (ç©ºæ¬„ã§æœ€æ–°)")
        time_range = st.slider("ã‚°ãƒ©ãƒ•è¡¨ç¤ºæ™‚é–“å¸¯", 0, 23, (9, 19)) # è¡¨ç¤ºç¯„å›²ã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã‚’è¿½åŠ 
        
    st.markdown("---")
    run_btn = st.button("ğŸš€ æ³¢ã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’è§£æ", type="primary", use_container_width=True)

freq_td = pd.Timedelta(RESAMPLE_FREQ)
ahead_steps = max(1, int(pd.Timedelta(minutes=PREDICT_AHEAD_MINS) / freq_td))
TARGET_DATETIME = TARGET_DATETIME_STR if TARGET_DATETIME_STR.strip() != "" else None

# === ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===
if run_btn or file_ts is not None:
    if file_ts is None:
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œç”Ÿä½“ãƒ‡ãƒ¼ã‚¿ã€ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
        
    with st.spinner("AIãŒé›†ä¸­ã‚’ã€æ³¢ã€ã¨ã—ã¦è§£æä¸­..."):
        # 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        df_ts_raw = pd.read_csv(io.BytesIO(file_ts.getvalue()), skiprows=2)
        df_ts_raw['timestamp_clean'] = df_ts_raw['timestamp'].astype(str).str.split(' GMT').str[0]
        df_ts_raw['datetime'] = pd.to_datetime(df_ts_raw['timestamp_clean'], errors='coerce')
        df_ts_raw = df_ts_raw.dropna(subset=['datetime']).set_index('datetime').sort_index()

        df_sched_raw = None
        if file_sched:
            df_sched_raw = pd.read_csv(io.BytesIO(file_sched.getvalue()))
            df_sched_raw = df_sched_raw[df_sched_raw['çµ‚æ—¥ã‚¤ãƒ™ãƒ³ãƒˆ'].astype(str).str.upper() != 'TRUE']
            df_sched_raw['start_dt'] = pd.to_datetime(df_sched_raw['é–‹å§‹æ—¥'].astype(str) + ' ' + df_sched_raw['é–‹å§‹æ™‚åˆ»'].astype(str), errors='coerce')
            df_sched_raw['end_dt']   = pd.to_datetime(df_sched_raw['çµ‚äº†æ—¥'].astype(str) + ' ' + df_sched_raw['çµ‚äº†æ™‚åˆ»'].astype(str), errors='coerce')
            df_sched_raw = df_sched_raw.dropna(subset=['start_dt', 'end_dt']).sort_values('start_dt')
            
        # 2. å‰å‡¦ç†ãƒ»ç‰¹å¾´é‡ä½œæˆ
        num_cols = df_ts_raw.select_dtypes(include=[np.number]).columns
        df_resampled = df_ts_raw[num_cols].resample(RESAMPLE_FREQ).mean()
        if '1åˆ†é–“æ­©æ•°' in df_ts_raw.columns:
            df_resampled['1åˆ†é–“æ­©æ•°'] = df_ts_raw['1åˆ†é–“æ­©æ•°'].resample(RESAMPLE_FREQ).sum()
            
        df_feat, q70_thresh = make_wave_features(df_resampled, df_sched_raw, freq_td)
        
        # åŸºæº–æ—¥æ™‚ã®æ±ºå®š
        if TARGET_DATETIME:
            try:
                current_time = pd.to_datetime(TARGET_DATETIME)
                target_data_all = df_feat[df_feat.index <= current_time]
                target_data = target_data_all.iloc[-1:] if not target_data_all.empty else df_feat.iloc[-1:]
            except:
                target_data = df_feat.iloc[-1:]
        else:
            target_data = df_feat.iloc[-1:]
        current_time = target_data.index[0]
        
        # 3. æŒ‡æ¨™ã®è¨ˆç®—
        metrics = compute_personal_metrics(df_feat, freq_td, current_time)
        
        # 4. äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨æ¨è«–
        model, feature_cols, eval_metrics, df_model = train_predict_classifier(df_feat, ahead_steps)
        
        focus_prob = 0.0
        if model is not None:
            focus_prob = model.predict_proba(target_data[feature_cols])[0, 1]

        # --- ç¾åœ¨ã®æ³¢ã®ä½ç›¸ã¨æ¬¡ãƒ”ãƒ¼ã‚¯æ¨è¨ˆ ---
        current_phase = target_data['phase_str'].values[0]
        avg_period = metrics['avg_wave_period']
        
        last_peak_time_val = target_data['last_peak_time'].values[0]
        if pd.notna(last_peak_time_val):
            last_peak_dt = pd.to_datetime(last_peak_time_val)
            mins_since_peak = (current_time - last_peak_dt).total_seconds() / 60
            next_peak_in = max(0, int(avg_period - mins_since_peak))
        else:
            next_peak_in = int(avg_period)

        # --- æ¬¡ã®Deep Workãƒãƒ£ãƒ³ã‚¹ç®—å‡º ---
        next_chance_text = "æœ¬æ—¥ã¯çµ‚äº†ã€ã¾ãŸã¯ç©ºãæ™‚é–“ãŒã‚ã‚Šã¾ã›ã‚“"
        if current_time.hour < 19:
            end_of_day = current_time.replace(hour=19, minute=0, second=0)
            future_mask = (df_feat.index > current_time) & (df_feat.index <= end_of_day) & (df_feat['has_schedule'] == 0)
            future_blank_times = df_feat[future_mask].index
            
            if not future_blank_times.empty:
                blank_blocks = (future_mask != future_mask.shift()).cumsum()[future_mask]
                longest_block_id = blank_blocks.value_counts().idxmax()
                best_block_times = future_blank_times[blank_blocks == longest_block_id]
                if len(best_block_times) > 0:
                    c_start = best_block_times[0]
                    c_end = best_block_times[-1] + freq_td
                    next_chance_text = f"{c_start.strftime('%H:%M')} â€“ {c_end.strftime('%H:%M')}"

    # ==========================================
    # UI æç”»
    # ==========================================
    st.markdown(f"<p style='text-align: right; color: gray;'>æœ€çµ‚æ›´æ–°: {current_time.strftime('%Y/%m/%d %H:%M')}</p>", unsafe_allow_html=True)
    
    tab_today, tab_weekly, tab_spec = st.tabs(["ğŸŒŠ Today (æ³¢ã¨æˆæœã®ç®¡ç†)", "ğŸ“Š Weekly Report", "ğŸ‘¤ My Spec (æ³¢ã®ç‰¹æ€§)"])

    # --- TAB 1: Today (æ„æ€æ±ºå®šæ”¯æ´UI) ---
    with tab_today:
        col_m1, col_m2, col_m3 = st.columns([1, 1, 1])
        
        with col_m1:
            # ãƒ¡ã‚¤ãƒ³KPI: Deep Worké€²æ—
            remain_dw = max(0, metrics['target_dw_mins'] - metrics['today_dw_mins'])
            achieved_color = "ğŸŸ¢ ç›®æ¨™ã‚¯ãƒªã‚¢ï¼" if remain_dw == 0 else f"ç›®æ¨™ã¾ã§ã‚ã¨ {remain_dw} åˆ†"
            
            st.markdown(f"""
            <div class="kpi-card" style="border-top: 5px solid #0f172a; height: 100%;">
                <div class="kpi-title">ä»Šæ—¥ã®Deep Worké”æˆçŠ¶æ³</div>
                <div class="kpi-value-main">
                    {int(metrics['today_dw_mins'])} <span class="kpi-unit">/ {metrics['target_dw_mins']} åˆ†</span>
                </div>
                <div class="kpi-sub {'alert' if remain_dw > 60 else ''}">{achieved_color}</div>
            </div>
            """, unsafe_allow_html=True)
            
        with col_m2:
            # é›†ä¸­ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ (æ³¢ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹)
            phase_color = "#ef4444" if "ä¸‹é™" in current_phase else "#10b981" if "ä¸Šæ˜‡" in current_phase else "#64748b"
            st.markdown(f"""
            <div class="kpi-card" style="border-top: 5px solid #3b82f6; height: 100%;">
                <div class="kpi-title">ç¾åœ¨ã®é›†ä¸­æ³¢ãƒ•ã‚§ãƒ¼ã‚º</div>
                <div class="kpi-value-wave" style="color: {phase_color};">{current_phase}</div>
                <div class="kpi-sub" style="color:#64748b; font-weight:normal;">æ¬¡ã®é›†ä¸­ãƒ”ãƒ¼ã‚¯äºˆæƒ³: ç´„ <strong>{next_peak_in} åˆ†å¾Œ</strong></div>
            </div>
            """, unsafe_allow_html=True)
            
        with col_m3:
            # AIäºˆæ¸¬
            prob_color = "#10b981" if focus_prob > 0.6 else "#f59e0b" if focus_prob > 0.4 else "#ef4444"
            st.markdown(f"""
            <div class="kpi-card" style="border-top: 5px solid #8b5cf6; height: 100%;">
                <div class="kpi-title">{PREDICT_AHEAD_MINS}åˆ†å¾Œã® é«˜é›†ä¸­æ³¢ å†çªå…¥ç¢ºç‡</div>
                <div class="kpi-value-main" style="color: {prob_color};">{focus_prob * 100:.1f} <span class="kpi-unit">%</span></div>
                <div class="kpi-sub" style="color:#64748b; font-weight:normal;">ä¸Šä½30%ã®ã‚¾ãƒ¼ãƒ³ã«åˆ°é”ã™ã‚‹ç¢ºç‡</div>
            </div>
            """, unsafe_allow_html=True)
            
        # ä¸‹æ®µ: æ”¹å–„ä½™åœ°ã¨ãƒãƒ£ãƒ³ã‚¹
        col_s1, col_s2 = st.columns([1, 1.5])
        with col_s1:
            loss_status = "alert" if metrics['today_dw_loss'] >= 30 else "warning" if metrics['today_dw_loss'] > 0 else ""
            st.markdown(f"""
            <div style="display: flex; gap: 10px;">
                <div class="kpi-card" style="flex: 1; padding: 15px;">
                    <div class="kpi-title" style="font-size:0.85rem;">ç©ºç™½æ™‚é–“ã®é›†ä¸­ç‡</div>
                    <div style="font-size:1.8rem; font-weight:bold; color:#334155;">{metrics['today_dw_rate']:.1f} <span style="font-size:1rem;">%</span></div>
                </div>
                <div class="kpi-card" style="flex: 1; padding: 15px;">
                    <div class="kpi-title" style="font-size:0.85rem;">åˆ†æ–­ãƒ­ã‚¹(æ³¢ã®é “æŒ«)</div>
                    <div style="font-size:1.8rem; font-weight:bold; color:#334155;">{int(metrics['today_dw_loss'])} <span style="font-size:1rem;">åˆ†</span></div>
                </div>
            </div>
            """, unsafe_allow_html=True)
        with col_s2:
            st.markdown(f"""
            <div class="chance-box" style="margin-bottom: 0;">
                <div class="kpi-title" style="color: #047857;">ğŸ¯ æ¬¡ã®Deep Workãƒãƒ£ãƒ³ã‚¹æ </div>
                <div class="chance-time">{next_chance_text}</div>
                <div style="font-size: 0.95rem; color: #065f46; margin-top: 8px;">ã“ã®æ™‚é–“ã‚’æ­»å®ˆã—ã€æ³¢ã«ä¹—ã£ã¦é‡è¦ã‚¿ã‚¹ã‚¯ã‚’æ¶ˆåŒ–ã—ã¦ãã ã•ã„ã€‚</div>
            </div>
            """, unsafe_allow_html=True)

        st.markdown("---")
        st.markdown("### ğŸ›  æ³¢ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        
        sim_c1, sim_c2 = st.columns(2)
        with sim_c1:
            st.markdown("""
            <div class="sim-box">
                <h4>ğŸš« ä¼šè­°ã‚’30åˆ†çŸ­ç¸®ãƒ»ãƒ–ãƒ­ãƒƒã‚¯åŒ–ã™ã‚‹</h4>
                <p style="color:#555;">æ³¢ãŒåˆ†æ–­ã•ã‚Œã‚‹ã®ã‚’é˜²ãã“ã¨ã§ã€éå»ã®æˆåŠŸç‡ã‹ã‚‰æ›ç®—ã—ã¦ã€<br>
                ä»Šæ—¥ã®Deep Workç·é‡ãŒ <strong style="color:#10b981; font-size:1.2rem;">å¢—åŠ ã—ã¾ã™</strong>ã€‚</p>
            </div>
            """, unsafe_allow_html=True)
        with sim_c2:
            st.markdown("""
            <div class="sim-box">
                <h4>â˜• ä»Šã‹ã‚‰15åˆ†ã€å®Œå…¨ãªä¼‘æ†©ã‚’ã¨ã‚‹</h4>
                <p style="color:#555;">æ³¢ã®æŒ¯å¹…ï¼ˆå¼·ã•ï¼‰ã‚’å›å¾©ã•ã›ã‚‹ã“ã¨ã§ã€æ¬¡ã®é«˜é›†ä¸­æ³¢ã®æŒç¶šæ™‚é–“ãŒ<br>
                é€šå¸¸ã‚ˆã‚Š <strong style="color:#10b981; font-size:1.2rem;">å»¶é•·ã•ã‚Œã‚‹è¦‹è¾¼ã¿</strong> ã§ã™ã€‚</p>
            </div>
            """, unsafe_allow_html=True)

    # --- TAB 2: Weekly Report ---
    with tab_weekly:
        st.markdown("## ä»Šé€±ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨æ³¢ã®æŒ¯ã‚Šè¿”ã‚Š")
        
        past_7_days = current_time.date() - pd.Timedelta(days=7)
        past_14_days = current_time.date() - pd.Timedelta(days=14)
        
        df_this_week = df_feat[(df_feat['date'] > past_7_days) & (df_feat['date'] <= current_time.date())]
        df_last_week = df_feat[(df_feat['date'] > past_14_days) & (df_feat['date'] <= past_7_days)]
        
        tw_dw = df_this_week['deep_work'].sum() * (freq_td.total_seconds() / 60)
        lw_dw = df_last_week['deep_work'].sum() * (freq_td.total_seconds() / 60)
        diff_dw = tw_dw - lw_dw
        
        st.metric("ä»Šé€±ã®Deep Workåˆè¨ˆæ™‚é–“", f"{int(tw_dw)} åˆ†", f"{'+' if diff_dw>=0 else ''}{int(diff_dw)} åˆ† (å…ˆé€±æ¯”)")
        
        # --- é»„é‡‘ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å‹•çš„æŠ½å‡ºï¼ˆæœ€å¤§3ã¤ï¼‰ ---
        st.markdown("#### ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‘ãŸé»„é‡‘ãƒ‘ã‚¿ãƒ¼ãƒ³")
        
        # éå»ãƒ‡ãƒ¼ã‚¿å…¨ä½“ï¼ˆå¹³æ—¥ï¼‰ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ç´¢
        df_feat_wd = df_feat[df_feat['dayofweek'] < 5].copy()
        if not df_feat_wd.empty and df_feat_wd['date'].nunique() >= 3:
            daily_stats = []
            for d, group in df_feat_wd.groupby('date'):
                am_group = group[group.index.hour < 12]
                pm_group = group[group.index.hour >= 12]
                
                dw_mins = group['deep_work'].sum() * (freq_td.total_seconds() / 60)
                am_dw_mins = am_group['deep_work'].sum() * (freq_td.total_seconds() / 60)
                am_meeting = am_group['is_meeting'].sum() * (freq_td.total_seconds() / 60)
                pm_blank = (pm_group['has_schedule'] == 0).sum() * (freq_td.total_seconds() / 60)
                steps = group['1åˆ†é–“æ­©æ•°'].sum() if '1åˆ†é–“æ­©æ•°' in group.columns else 0
                
                # æœ€é•·ç©ºç™½ãƒ–ãƒ­ãƒƒã‚¯
                blank_mask = group['has_schedule'] == 0
                blank_blocks = blank_mask.groupby((blank_mask != blank_mask.shift()).cumsum()).sum()
                longest_blank = blank_blocks.max() * (freq_td.total_seconds() / 60) if not blank_blocks.empty else 0
                
                daily_stats.append({
                    'date': d,
                    'dw_mins': dw_mins,
                    'am_dw_mins': am_dw_mins,
                    'am_meeting': am_meeting,
                    'pm_blank': pm_blank,
                    'steps': steps,
                    'longest_blank': longest_blank
                })
                
            df_daily = pd.DataFrame(daily_stats)
            avg_dw_all = df_daily['dw_mins'].mean()
            
            if avg_dw_all > 0:
                patterns = []
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³1: åˆå‰ã«ä¼šè­°é›†ä¸­ã€åˆå¾Œç©ºç™½
                m_am = df_daily['am_meeting'].median()
                m_pm = df_daily['pm_blank'].median()
                mask1 = (df_daily['am_meeting'] >= m_am) & (df_daily['pm_blank'] >= m_pm) & (df_daily['am_meeting'] > 0)
                if mask1.sum() >= 1 and (~mask1).sum() >= 1:
                    avg_dw = df_daily[mask1]['dw_mins'].mean()
                    if avg_dw > avg_dw_all * 1.05:
                        patterns.append((avg_dw / avg_dw_all, "åˆå‰ä¸­ã«ä¼šè­°ã‚’å¯„ã›ã¦ã€åˆå¾Œã«ã¾ã¨ã¾ã£ãŸç©ºç™½ã‚’ä½œã£ãŸæ—¥"))
                        
                # ãƒ‘ã‚¿ãƒ¼ãƒ³2: èº«ä½“æ´»å‹•
                if df_daily['steps'].max() > 0:
                    m_steps = df_daily['steps'].median()
                    mask2 = df_daily['steps'] > m_steps
                    if mask2.sum() >= 1 and (~mask2).sum() >= 1:
                        avg_dw = df_daily[mask2]['dw_mins'].mean()
                        if avg_dw > avg_dw_all * 1.05:
                            patterns.append((avg_dw / avg_dw_all, "èº«ä½“ã‚’å‹•ã‹ã—æ´»å‹•é‡ï¼ˆæ­©æ•°ï¼‰ã‚’å¹³å‡ä»¥ä¸Šã«ç¢ºä¿ã—ãŸæ—¥"))
                            
                # ãƒ‘ã‚¿ãƒ¼ãƒ³3: 90åˆ†ãƒ–ãƒ­ãƒƒã‚¯
                mask3 = df_daily['longest_blank'] >= 90
                if mask3.sum() >= 1 and (~mask3).sum() >= 1:
                    avg_dw = df_daily[mask3]['dw_mins'].mean()
                    if avg_dw > avg_dw_all * 1.05:
                        patterns.append((avg_dw / avg_dw_all, "1æ—¥ã®ã©ã“ã‹ã§ã€Œ90åˆ†ä»¥ä¸Šã®é€£ç¶šã—ãŸç©ºç™½æ ã€ã‚’æ­»å®ˆã—ãŸæ—¥"))
                        
                # ãƒ‘ã‚¿ãƒ¼ãƒ³4: åˆå‰ä¸­ã®DWã‚¹ã‚¿ãƒ¼ãƒˆ
                mask4 = df_daily['am_dw_mins'] > 0
                if mask4.sum() >= 1 and (~mask4).sum() >= 1:
                    avg_dw = df_daily[mask4]['dw_mins'].mean()
                    if avg_dw > avg_dw_all * 1.05:
                        patterns.append((avg_dw / avg_dw_all, "åˆå‰ä¸­ã®ã†ã¡ã«1å›ã§ã‚‚Deep Workã®æ³¢ã«ä¹—ã‚ŒãŸæ—¥"))
                        
                # åŠ¹æœãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆã—ã€æœ€å¤§3ã¤ã‚’å–å¾—
                patterns.sort(key=lambda x: x[0], reverse=True)
                top_patterns = patterns[:3]
                
                if top_patterns:
                    icons = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"]
                    for i, (ratio, text) in enumerate(top_patterns):
                        st.info(f"{icons[i]} **ã€Œ{text}ã€** ã¯ã€æ³¢ãŒé€”åˆ‡ã‚ŒãšDeep Workæ™‚é–“ãŒå¹³å‡ã® **{ratio:.1f}å€** ã«ãªã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")
                else:
                    st.info("ğŸ’¡ å®‰å®šã—ãŸæˆæœã‚’å‡ºã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ãƒ‡ãƒ¼ã‚¿ãŒè“„ç©ã•ã‚Œã‚‹ã¨ã€ã‚ãªãŸå°‚ç”¨ã®ã€ŒDeep WorkãŒå€å¢—ã™ã‚‹é»„é‡‘ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ãŒã“ã“ã«æœ€å¤§3ã¤è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
            else:
                st.info("ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ã®è“„ç©ãŒé€²ã‚€ã¨ã€ã‚ãªãŸå°‚ç”¨ã®ã€ŒDeep WorkãŒå€å¢—ã™ã‚‹é»„é‡‘ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
        else:
            st.info("ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ãŒååˆ†ã«è“„ç©ã•ã‚Œã‚‹ã¨ã€ã‚ãªãŸå°‚ç”¨ã®ã€ŒDeep WorkãŒå€å¢—ã™ã‚‹é»„é‡‘ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ï¼ˆâ€»æ¯”è¼ƒã®ãŸã‚æ•°æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ï¼‰")

        # --- æ³¢å½¢ã‚°ãƒ©ãƒ• (ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ«ã‚°ãƒ©ãƒ•) ã®å¾©æ´»ãƒ»é€²åŒ–ç‰ˆ ---
        st.markdown("---")
        st.markdown("#### ğŸŒŠ ä»Šé€±ã®é›†ä¸­æ³¢å½¢ (ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ«ã‚°ãƒ©ãƒ•)")
        st.caption("â€» é’ã„ç·šãŒå¹³æ»‘åŒ–ã•ã‚ŒãŸé›†ä¸­ã®ã€Œæ³¢ã€ã‚’è¡¨ã—ã€èµ¤ã„ç‚¹ãŒAIãŒæ¤œå‡ºã—ãŸã€Œæ³¢ã®ãƒ”ãƒ¼ã‚¯ã€ã§ã™ã€‚ã‚°ãƒ¬ãƒ¼ã®ç‚¹ç·šã‚ˆã‚Šä¸Šã®é’ã„é¢ãŒã€Œé«˜é›†ä¸­ã‚¾ãƒ¼ãƒ³ï¼ˆDeep Workã®å€™è£œï¼‰ã€ã§ã™ã€‚æ³¢ã®å‘¨æœŸæ€§ï¼ˆãƒªã‚ºãƒ ï¼‰ãŒè¦–è¦šçš„ã«ç¢ºèªã§ãã¾ã™ã€‚")
        
        week_dates = df_this_week['date'].unique()
        if len(week_dates) > 0:
            for i in range(0, len(week_dates), 2):
                cols = st.columns(2)
                for j in range(2):
                    if i + j < len(week_dates):
                        t_date = week_dates[i+j]
                        with cols[j]:
                            df_day = df_this_week[df_this_week['date'] == t_date].copy()
                            # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã—ãŸæ™‚é–“å¸¯ã§ãƒ•ã‚£ãƒ«ã‚¿
                            df_day = df_day[(df_day.index.hour >= time_range[0]) & (df_day.index.hour <= time_range[1])]
                            
                            if not df_day.empty and not df_day['focus_smooth'].isna().all():
                                fig_d = go.Figure()
                                
                                # åŸºæº–ç·š (é«˜é›†ä¸­ãƒ©ã‚¤ãƒ³: ä¸Šä½30%ã®é–¾å€¤)
                                q70_val = q70_thresh 
                                fig_d.add_trace(go.Scatter(x=df_day.index, y=[q70_val]*len(df_day), mode='lines', line=dict(color='gray', width=1, dash='dash'), name='é«˜é›†ä¸­ãƒ©ã‚¤ãƒ³', hoverinfo='skip'))
                                
                                # é–¾å€¤ã‚ˆã‚Šä¸Šã®éƒ¨åˆ†ã‚’é’ãå¡—ã‚Šã¤ã¶ã— (Deep Work ã‚¾ãƒ¼ãƒ³)
                                y_up = np.where(df_day['focus_smooth'] >= q70_val, df_day['focus_smooth'], q70_val)
                                fig_d.add_trace(go.Scatter(x=df_day.index, y=y_up, fill='tonexty', fillcolor='rgba(59, 130, 246, 0.3)', mode='lines', line=dict(width=0), hoverinfo='skip', showlegend=False))
                                # ä¸‹å´ã‚’é€æ˜ã«ã™ã‚‹ãŸã‚ã®ãƒ€ãƒŸãƒ¼ãƒˆãƒ¬ãƒ¼ã‚¹
                                fig_d.add_trace(go.Scatter(x=df_day.index, y=[q70_val]*len(df_day), fill='tonexty', fillcolor='rgba(0,0,0,0)', mode='lines', line=dict(width=0), hoverinfo='skip', showlegend=False))
                                
                                # æ³¢ã®ç·š (ãƒ¡ã‚¤ãƒ³)
                                fig_d.add_trace(go.Scatter(x=df_day.index, y=df_day['focus_smooth'], mode='lines', line=dict(color='#3b82f6', width=2), name='é›†ä¸­æ³¢', hovertemplate="%{x|%H:%M}<br>å¼·åº¦: %{y:.1f}<extra></extra>"))
                                
                                # ãƒ”ãƒ¼ã‚¯ã®ãƒã‚¤ãƒ³ãƒˆ (èµ¤ã„ç‚¹)
                                peaks_day = df_day[df_day['is_peak'] == 1]
                                if not peaks_day.empty:
                                    fig_d.add_trace(go.Scatter(x=peaks_day.index, y=peaks_day['focus_smooth'], mode='markers', marker=dict(color='#ef4444', size=6, symbol='circle'), name='ãƒ”ãƒ¼ã‚¯', hovertemplate="%{x|%H:%M}<br>ãƒ”ãƒ¼ã‚¯<extra></extra>"))
                                
                                dow_str = ['æœˆ','ç«','æ°´','æœ¨','é‡‘','åœŸ','æ—¥'][t_date.weekday()]
                                fig_d.update_layout(title=f"{t_date.strftime('%m/%d')} ({dow_str})", height=250, hovermode="x unified", plot_bgcolor='rgba(0,0,0,0)', margin=dict(l=20, r=20, t=30, b=20), showlegend=False)
                                fig_d.update_xaxes(showgrid=True, gridcolor='lightgray')
                                
                                # Yè»¸ã®ç¯„å›²ã‚’é©åº¦ã«èª¿æ•´
                                y_min = df_day['focus_smooth'].min()
                                y_max = df_day['focus_smooth'].max()
                                amp = y_max - y_min if y_max - y_min > 0 else 10
                                fig_d.update_yaxes(showgrid=True, gridcolor='lightgray', title="é›†ä¸­å¼·åº¦", range=[max(0, y_min - amp*0.2), y_max + amp*0.2])
                                
                                st.plotly_chart(fig_d, use_container_width=True)
                            else:
                                st.markdown(f"**{t_date.strftime('%m/%d')} ({['æœˆ','ç«','æ°´','æœ¨','é‡‘','åœŸ','æ—¥'][t_date.weekday()]})**")
                                st.info("æŒ‡å®šã•ã‚ŒãŸæ™‚é–“å¸¯ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    # --- TAB 3: My Spec ---
    with tab_spec:
        st.markdown("## ğŸ‘¤ ã‚ãªãŸã®ã€Œé›†ä¸­ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã€æ”»ç•¥æ³•")
        st.write("éå»ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’æ³¢å½¢è§£æã—ã€ã‚ãªãŸå›ºæœ‰ã®é›†ä¸­ãƒªã‚ºãƒ ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")
        
        best_hour = df_feat.groupby('hour')['deep_work'].sum().idxmax()
        
        c_spec1, c_spec2, c_spec3 = st.columns(3)
        c_spec1.metric("â± å¹³å‡é›†ä¸­æ³¢ å‘¨æœŸ", f"{int(metrics['avg_wave_period'])} åˆ†", "æ³¢ãŒè¨ªã‚Œã‚‹é–“éš”")
        c_spec2.metric("ğŸ¯ æœ€é©é›†ä¸­æ™‚é–“å¸¯", f"{best_hour}:00 å°", "æ³¢ãŒæœ€å¤§åŒ–ã™ã‚‹æ™‚é–“")
        c_spec3.metric("ğŸ“ˆ æ³¢ã®å¹³å‡æŒ¯å¹…", f"{metrics['avg_wave_amplitude']:.1f} pt", "é›†ä¸­ã®æ·±ã•ã®æŒ‡æ¨™")
        
        st.markdown("""
        <div style="background-color: #f8fafc; padding: 20px; border-radius: 8px; border-left: 4px solid #3b82f6; margin-top: 20px;">
            <h4>ğŸ“ AIã‹ã‚‰ã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«ã‚³ãƒ¡ãƒ³ãƒˆ</h4>
            <ul style="font-size: 1.1rem; color: #334155; line-height: 1.6;">
                <li>ã‚ãªãŸã®é›†ä¸­ã¯<strong>ç´„ {0} åˆ†å‘¨æœŸ</strong>ã®æ³¢ã‚’æã„ã¦ã„ã¾ã™ã€‚ç–²ã‚ŒãŸæ™‚ã¯ç„¡ç†ã‚’ã›ãšã€æ¬¡ã®æ³¢ãŒæ¥ã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«åˆã‚ã›ã¦ä½œæ¥­ã‚’å†é–‹ã™ã‚‹ã®ãŒåŠ¹ç‡çš„ã§ã™ã€‚</li>
                <li><strong>{1}æ™‚å°</strong>ã«æ³¢ã®æŒ¯å¹…ãŒæœ€å¤§åŒ–ã—ã€æ¥µã‚ã¦æ·±ã„é›†ä¸­çŠ¶æ…‹ã«å…¥ã‚Šã‚„ã™ããªã‚Šã¾ã™ã€‚ã“ã®æ™‚é–“å¸¯ã¯æ­»å®ˆã—ã¦ãã ã•ã„ã€‚</li>
                <li>äºˆå®šã®åˆé–“ãŒçŸ­ã™ãã‚‹ã¨ã€æ³¢ãŒä¸Šæ˜‡ã—ãã‚‹å‰ã«åˆ†æ–­ã•ã‚Œã¦ã—ã¾ã†ã€Œåˆ†æ–­ãƒ­ã‚¹ã€ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚ä¼šè­°ã¯å›ºã‚ã¦é…ç½®ã—ã¾ã—ã‚‡ã†ã€‚</li>
            </ul>
        </div>
        """.format(int(metrics['avg_wave_period']), best_hour), unsafe_allow_html=True)

    # --- é–‹ç™ºè€…å‘ã‘ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
    with st.expander("ğŸ›  é–‹ç™ºè€…å‘ã‘æƒ…å ± (ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ»SHAPãƒ»ç‰¹å¾´é‡)"):
        st.markdown("### ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™ (åˆ†é¡ãƒ¢ãƒ‡ãƒ«)")
        col_ev1, col_ev2, col_ev3 = st.columns(3)
        if eval_metrics:
            col_ev1.metric("ROC-AUC", f"{eval_metrics.get('ROC-AUC', 0):.3f}")
            col_ev2.metric("PR-AUC", f"{eval_metrics.get('PR-AUC', 0):.3f}")
            col_ev3.metric("F1 Score", f"{eval_metrics.get('F1 Score', 0):.3f}")
        else:
            st.warning("è©•ä¾¡ã«å¿…è¦ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆæ­£ä¾‹ãƒ»è² ä¾‹ï¼‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
            
        st.markdown("### ç›´è¿‘äºˆæ¸¬ã®æ ¹æ‹  (SHAP)")
        st.write("æ³¢ã®ç‰¹å¾´é‡ï¼ˆå‘¨æœŸãƒ»æŒ¯å¹…ãƒ»ä½ç›¸ï¼‰ã‚„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¦å› ãŒã€ç¢ºç‡ã‚’ã©ã®ã‚ˆã†ã«æŠ¼ã—ä¸Šã’ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚")
        if model is not None:
            explainer = shap.TreeExplainer(model)
            shap_values = explainer(target_data[feature_cols])
            
            fig_shap, ax_shap = plt.subplots(figsize=(8, 4))
            if len(shap_values.shape) == 3:
                shap.plots.waterfall(shap_values[0, :, 1], show=False)
            else:
                shap.plots.waterfall(shap_values[0], show=False)
            st.pyplot(fig_shap)