# -*- coding: utf-8 -*-
"""
ã‚¦ã‚§ã‚¢ãƒ©ãƒ–ãƒ« + Outlookã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« é›†ä¸­ãƒ»ç–²åŠ´äºˆæ¸¬ã‚¢ãƒ—ãƒª (V2: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç‰¹åŒ–å‹ + ã‚¤ãƒ³ã‚µã‚¤ãƒˆå……å®Ÿç‰ˆ)
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import lightgbm as lgb
from sklearn.metrics import roc_auc_score, log_loss
from sklearn.tree import DecisionTreeRegressor, _tree
import google.generativeai as genai
import shap
import warnings
import plotly.graph_objects as go
import plotly.express as px
from pathlib import Path
import matplotlib as mpl
import matplotlib.font_manager as fm
import datetime
import math

# --- Streamlit ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Focus Battery | é›†ä¸­äºˆæ¸¬", layout="wide", initial_sidebar_state="expanded")

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
font_path = Path(__file__).parent / "assets" / "fonts" / "NotoSansCJKjp-Regular.otf"
if font_path.exists():
    fm.fontManager.addfont(str(font_path))
    prop = fm.FontProperties(fname=str(font_path))
    mpl.rcParams["font.family"] = prop.get_name()

mpl.rcParams["axes.unicode_minus"] = False
warnings.filterwarnings('ignore')

# --- ã‚«ã‚¹ã‚¿ãƒ CSS (UIã®æ´—ç·´) ---
st.markdown("""
<style>
    .metric-container { background-color: #f8f9fa; border-radius: 10px; padding: 20px; text-align: center; box-shadow: 0 4px 6px rgba(0,0,0,0.05); margin-bottom: 20px; }
    .metric-title { font-size: 1.2rem; color: #6c757d; margin-bottom: 5px; font-weight: 600; }
    .metric-value { font-size: 3.5rem; color: #2b2b2b; font-weight: 800; line-height: 1.2; }
    .metric-sub { font-size: 1rem; color: #28a745; font-weight: bold; }
    .metric-sub.negative { color: #dc3545; }
    .window-box { background-color: #e3f2fd; border-left: 5px solid #1976d2; padding: 20px; border-radius: 5px; margin-bottom: 20px; }
    .window-time { font-size: 2rem; color: #1976d2; font-weight: 800; }
</style>
""", unsafe_allow_html=True)

# --- ç‰¹å¾´é‡åæ—¥æœ¬èªåŒ–ãƒ˜ãƒ«ãƒ‘ãƒ¼ ---
def jp_feat_name(col_name: str) -> str:
    mapping = {'CVRR_SCORE_NEW': 'é›†ä¸­ã‚¹ã‚³ã‚¢', '1åˆ†é–“æ­©æ•°': 'æ­©æ•°', 'is_meeting': 'ä¼šè­°', 'schedule_density_2h': 'äºˆå®šå¯†åº¦', 'ä¼‘æ†©åˆ¤å®š': 'ä¼‘æ†©', 'çŸ­æ™‚é–“æ­©è¡Œ': 'çŸ­æ™‚é–“æ­©è¡Œ'}
    for k, v in mapping.items():
        if k in col_name: return col_name.replace(k, v)
    return col_name

def get_base_feature_name(feat: str) -> str:
    mapping = {'CVRR_SCORE_NEW': 'é›†ä¸­ã‚¹ã‚³ã‚¢', '1åˆ†é–“æ­©æ•°': 'æ­©æ•°', 'is_meeting': 'ä¼šè­°', 'schedule_density_2h': 'äºˆå®šå¯†åº¦', 'ä¼‘æ†©åˆ¤å®š': 'ä¼‘æ†©', 'çŸ­æ™‚é–“æ­©è¡Œ': 'çŸ­æ™‚é–“æ­©è¡Œ'}
    for k, v in mapping.items():
        if feat.startswith(k): return v
    return feat

def extract_rules(tree, feature_names, is_bool_list):
    tree_ = tree.tree_
    feature_name = [
        feature_names[i] if i != _tree.TREE_UNDEFINED else "undefined!"
        for i in tree_.feature
    ]
    rules = []
    def recurse(node, current_rule):
        if tree_.feature[node] != _tree.TREE_UNDEFINED:
            name = feature_name[node]
            threshold = tree_.threshold[node]
            is_bool = is_bool_list[tree_.feature[node]]
            
            left_rule = current_rule.copy()
            if is_bool:
                left_rule.append(f"ã€{name}ï¼šãªã—ã€‘")
            else:
                left_rule.append(f"ã€{name}ãŒä½ã„ (â‰¦{threshold:.2f})ã€‘")
            recurse(tree_.children_left[node], left_rule)
            
            right_rule = current_rule.copy()
            if is_bool:
                right_rule.append(f"ã€{name}ï¼šã‚ã‚Šã€‘")
            else:
                right_rule.append(f"ã€{name}ãŒé«˜ã„ (>{threshold:.2f})ã€‘")
            recurse(tree_.children_right[node], right_rule)
        else:
            val = tree_.value[node][0][0]
            samples = tree_.n_node_samples[node]
            rules.append((" ï¼‹ ".join(current_rule), val, samples))
    recurse(0, [])
    return rules

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ (è¨­å®šãƒ»ãƒ‡ãƒ¼ã‚¿å…¥åŠ›) ---
with st.sidebar:
    st.header("âš™ï¸ ãƒ‡ãƒ¼ã‚¿å…¥åŠ›")
    file_ts = st.file_uploader("1. ç”Ÿä½“ãƒ‡ãƒ¼ã‚¿ (CSV)", type=['csv'])
    file_sched = st.file_uploader("2. äºˆå®šè¡¨ãƒ‡ãƒ¼ã‚¿ (CSV)", type=['csv'])
    
    with st.expander("ğŸ›  è©³ç´°è¨­å®š (åˆ†æãƒ•ã‚£ãƒ«ã‚¿ç­‰)"):
        api_key = st.text_input("Gemini APIã‚­ãƒ¼", type="password")
        RESAMPLE_FREQ = st.selectbox("åˆ†æå˜ä½", ['10T', '30T', '1H'], index=1)
        PREDICT_AHEAD = st.selectbox("äºˆæ¸¬å…ˆ", ['10T', '30T', '1H'], index=1)
        TARGET_DATETIME_STR = st.text_input("äºˆæ¸¬åŸºæº–æ—¥æ™‚ (ç©ºæ¬„ã§æœ€æ–°)")
        target_col = 'é›†ä¸­åˆ¤å®š'
        
        st.markdown("**ğŸ“… åˆ†æå¯¾è±¡ãƒ•ã‚£ãƒ«ã‚¿**")
        dow_options = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"]
        selected_dows = st.multiselect("å¯¾è±¡æ›œæ—¥", dow_options, default=dow_options[0:5])
        time_range = st.slider("å¯¾è±¡æ™‚é–“å¸¯", 0, 23, (9, 19))
        
    st.markdown("---")
    st.button("ğŸš€ ä»Šæ—¥ã®ã‚³ãƒ³ãƒ‘ã‚¹ã‚’æ›´æ–°", type="primary", use_container_width=True, key="run_btn")

selected_dow_indices = [dow_options.index(d) for d in selected_dows]
freq_td = pd.Timedelta(RESAMPLE_FREQ)
ahead_steps = max(1, int(pd.Timedelta(PREDICT_AHEAD) / freq_td))
TARGET_DATETIME = TARGET_DATETIME_STR if TARGET_DATETIME_STR.strip() != "" else None

# --- åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ ---
@st.cache_data(show_spinner=False)
def load_and_preprocess(file_ts_bytes, file_sched_bytes):
    import io
    df_ts = pd.read_csv(io.BytesIO(file_ts_bytes), skiprows=2)
    df_ts['timestamp_clean'] = df_ts['timestamp'].astype(str).str.split(' GMT').str[0]
    df_ts['datetime'] = pd.to_datetime(df_ts['timestamp_clean'], errors='coerce')
    df_ts = df_ts.dropna(subset=['datetime']).set_index('datetime').sort_index()

    df_sched = None
    if file_sched_bytes:
        df_sched = pd.read_csv(io.BytesIO(file_sched_bytes))
        df_sched = df_sched[df_sched['çµ‚æ—¥ã‚¤ãƒ™ãƒ³ãƒˆ'].astype(str).str.upper() != 'TRUE']
        df_sched['start_dt'] = pd.to_datetime(df_sched['é–‹å§‹æ—¥'].astype(str) + ' ' + df_sched['é–‹å§‹æ™‚åˆ»'].astype(str), errors='coerce')
        df_sched['end_dt']   = pd.to_datetime(df_sched['çµ‚äº†æ—¥'].astype(str) + ' ' + df_sched['çµ‚äº†æ™‚åˆ»'].astype(str), errors='coerce')
        df_sched = df_sched.dropna(subset=['start_dt', 'end_dt']).sort_values('start_dt')

    return df_ts, df_sched

def run_ml_pipeline(df_ts, df_sched):
    num_cols = df_ts.select_dtypes(include=[np.number]).columns
    df_resampled = df_ts[num_cols].resample(RESAMPLE_FREQ).mean()
    if '1åˆ†é–“æ­©æ•°' in df_ts.columns:
        df_resampled['1åˆ†é–“æ­©æ•°'] = df_ts['1åˆ†é–“æ­©æ•°'].resample(RESAMPLE_FREQ).sum()

    if df_sched is not None:
        df_resampled['has_schedule'] = 0
        df_resampled['is_meeting'] = 0
        meeting_keywords = ['ä¼šè­°', 'æ‰“åˆã›', 'MTG', 'é¢è«‡']
        for _, row in df_sched.iterrows():
            mask = (df_resampled.index < row['end_dt']) & ((df_resampled.index + freq_td) > row['start_dt'])
            df_resampled.loc[mask, 'has_schedule'] = 1
            if any(kw in str(row.get('ä»¶å', '')) for kw in meeting_keywords):
                df_resampled.loc[mask, 'is_meeting'] = 1
        win_steps = max(1, int(pd.Timedelta('2H') / freq_td))
        df_resampled['schedule_density_2h'] = df_resampled['has_schedule'].rolling(win_steps, min_periods=1).mean()

    df_features = df_resampled.copy()
    if 'é›†ä¸­åˆ¤å®š' in df_features.columns:
        focus_mask = (df_features['é›†ä¸­åˆ¤å®š'] >= 0.5).astype(int)
        group_id = (focus_mask != focus_mask.shift()).cumsum()
        df_features['ç¾åœ¨ã®é›†ä¸­ç¶™ç¶šæ™‚é–“_åˆ†'] = (focus_mask.groupby(group_id).cumcount() + 1) * (freq_td.total_seconds() / 60) * focus_mask
    
    if 'ä¼‘æ†©åˆ¤å®š' in df_features.columns: df_features['ä¼‘æ†©åˆ¤å®š_å‰'] = df_features['ä¼‘æ†©åˆ¤å®š'].shift(1)
    if 'çŸ­æ™‚é–“æ­©è¡Œ' in df_features.columns: df_features['çŸ­æ™‚é–“æ­©è¡Œ_å‰'] = df_features['çŸ­æ™‚é–“æ­©è¡Œ'].shift(1)

    df_features['target_ahead'] = (df_features[target_col].shift(-ahead_steps) >= 0.5).astype(int)
    
    drop_cols = ['target_ahead']
    df_imp = df_features.ffill(limit=2).bfill(limit=2)
    train_df = df_imp.dropna(subset=drop_cols + [target_col])
    
    X = train_df.drop(columns=drop_cols)
    y = train_df['target_ahead']
    
    model = lgb.LGBMClassifier(objective='binary', n_estimators=100, learning_rate=0.05, random_state=42, verbose=-1)
    model.fit(X, y)
    
    return model, df_imp, X.columns, df_ts, df_sched

# === ãƒ¡ã‚¤ãƒ³å‡¦ç† ===
if st.session_state.get('run_btn') or (file_ts is not None):
    if file_ts is None:
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œ1. ç”Ÿä½“ãƒ‡ãƒ¼ã‚¿ã€ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
        
    with st.spinner("AIãŒã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚’è§£æä¸­..."):
        df_ts_raw, df_sched_raw = load_and_preprocess(file_ts.getvalue(), file_sched.getvalue() if file_sched else None)
        model, df_imp, feature_cols, df_ts_min, df_sched = run_ml_pipeline(df_ts_raw, df_sched_raw)
        
        # åŸºæº–æ—¥æ™‚ã®æ±ºå®š
        if TARGET_DATETIME is not None:
            try:
                current_time = pd.to_datetime(TARGET_DATETIME)
                target_data_all = df_imp[df_imp.index <= current_time]
                target_data = target_data_all.iloc[-1:] if not target_data_all.empty else df_imp.iloc[-1:]
            except:
                target_data = df_imp.iloc[-1:]
        else:
            target_data = df_imp.iloc[-1:]
        current_time = target_data.index[0]
            
        current_proba = model.predict_proba(target_data[feature_cols])[0, 1]
        
        # ==========================================
        # ğŸ”‹ Focus Battery ãƒ­ã‚¸ãƒƒã‚¯ (å˜èª¿æ¸›å°‘ï¼†ãƒ¬ãƒ³ã‚¸è¡¨ç¾ã«ä¿®æ­£)
        # ==========================================
        if 'é›†ä¸­åˆ¤å®š' in df_ts_min.columns:
            daily_focus = df_ts_min['é›†ä¸­åˆ¤å®š'].resample('D').apply(lambda x: (x >= 0.5).sum())
            daily_focus = daily_focus[daily_focus > 0] # è¨ˆæ¸¬ãŒãªã„æ—¥ã¯é™¤å¤–
            if not daily_focus.empty:
                avg_focus_mins = daily_focus.mean() # å¹³å‡å€¤ã‚’ãƒ™ãƒ¼ã‚¹ã«
                focus_p80 = daily_focus.quantile(0.80) # ä¸ŠæŒ¯ã‚Œï¼ˆ80%ã‚¿ã‚¤ãƒ«ãƒ»å¥½èª¿æ™‚ï¼‰
            else:
                avg_focus_mins, focus_p80 = 120, 180
        else:
            avg_focus_mins, focus_p80 = 120, 180
            
        today_str = current_time.strftime('%Y-%m-%d')
        if 'é›†ä¸­åˆ¤å®š' in df_ts_min.columns and today_str in df_ts_min.index.strftime('%Y-%m-%d'):
            today_data = df_ts_min[df_ts_min.index.date == current_time.date()]
            consumed_mins = (today_data.loc[:current_time, 'é›†ä¸­åˆ¤å®š'] >= 0.5).sum()
        else:
            consumed_mins = 0
            
        # ç¢ºç‡ã«ã‚ˆã‚‹å¤‰å‹•ã‚’å¤–ã—ã€ç´”ç²‹ã«ã€Œå…¨ä½“ã®ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ« - æ¶ˆåŒ–æ¸ˆã€ã§è¨ˆç®—
        rem_avg = max(0, int(avg_focus_mins - consumed_mins))
        rem_p80 = max(0, int(focus_p80 - consumed_mins))
        
        # ==========================================
        # ğŸ•’ Deep Work Window ãƒ­ã‚¸ãƒƒã‚¯
        # ==========================================
        window_text = "æœ¬æ—¥ã¯çµ‚äº†ãƒ¢ãƒ¼ãƒ‰ã§ã™"
        window_desc = "ã—ã£ã‹ã‚Šä¼‘ã‚“ã§æ˜æ—¥ã«å‚™ãˆã¾ã—ã‚‡ã†ã€‚"
        
        if current_time.hour < 19:
            start_search = current_time
            end_search = current_time.replace(hour=20, minute=0, second=0)
            free_blocks = []
            curr_block_start = start_search
            
            if df_sched is not None and not df_sched.empty:
                today_sched = df_sched[(df_sched['start_dt'] >= start_search) & (df_sched['start_dt'] < end_search)].sort_values('start_dt')
                for _, row in today_sched.iterrows():
                    if row['start_dt'] > curr_block_start:
                        duration = (row['start_dt'] - curr_block_start).total_seconds() / 60
                        if duration >= 60: free_blocks.append((curr_block_start, row['start_dt'], duration))
                    curr_block_start = max(curr_block_start, row['end_dt'])
                if curr_block_start < end_search:
                    duration = (end_search - curr_block_start).total_seconds() / 60
                    if duration >= 60: free_blocks.append((curr_block_start, end_search, duration))
            else:
                next_hour = current_time.replace(minute=0, second=0) + pd.Timedelta('1H')
                if next_hour < end_search: free_blocks.append((next_hour, next_hour + pd.Timedelta('90T'), 90))
                    
            if free_blocks:
                scored_blocks = []
                for b_start, b_end, duration in free_blocks:
                    sim_data = target_data[feature_cols].copy()
                    if 'hour' in sim_data.columns: sim_data['hour'] = b_start.hour
                    if 'is_meeting' in sim_data.columns: sim_data['is_meeting'] = 0
                    if 'has_schedule' in sim_data.columns: sim_data['has_schedule'] = 0
                    
                    block_proba = model.predict_proba(sim_data)[0, 1]
                    scored_blocks.append((b_start, b_end, duration, block_proba))
                
                best_block = sorted(scored_blocks, key=lambda x: x[3], reverse=True)[0]
                w_start = best_block[0]
                w_end = w_start + pd.Timedelta(minutes=min(90, best_block[2]))
                window_text = f"{w_start.strftime('%H:%M')} â€“ {w_end.strftime('%H:%M')}"
                window_desc = f"AIãŒæœ¬æ—¥æœ€ã‚‚é›†ä¸­ã—ã‚„ã™ã„ï¼ˆäºˆæ¸¬ç¢ºç‡ {best_block[3]*100:.1f}%ï¼‰ã¨åˆ¤æ–­ã—ãŸç©ºãæ™‚é–“ã§ã™ã€‚"

        fatigue_risk = False
        if 'ç–²åŠ´åˆ¤å®š' in target_data.columns and target_data['ç–²åŠ´åˆ¤å®š'].values[0] >= 0.5: fatigue_risk = True
        elif 'schedule_density_2h' in target_data.columns and target_data['schedule_density_2h'].values[0] >= 0.6: fatigue_risk = True

    # --- UI æç”»é–‹å§‹ ---
    st.markdown(f"<p style='text-align: right; color: gray;'>æ›´æ–°æ—¥æ™‚: {current_time.strftime('%Y/%m/%d %H:%M')}</p>", unsafe_allow_html=True)
    
    tab_today, tab_weekly, tab_spec = st.tabs(["ğŸ§­ Today's Compass (ä»Šæ—¥ã®è¡Œå‹•)", "ğŸ“Š Weekly Report (æŒ¯ã‚Šè¿”ã‚Š)", "ğŸ‘¤ My Spec (ã‚ãªãŸã®ç‰¹æ€§)"])

    # ==========================================
    # Tab 1: Today's Compass
    # ==========================================
    with tab_today:
        st.markdown("## 10ç§’ã§æ±ºã‚ã‚‹ã€ä»Šæ—¥ã®æœ€é©è§£")
        
        col1, col2 = st.columns([1.2, 1])
        with col1:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-title">ğŸ”‹ æœ¬æ—¥ã®é«˜å“è³ªé›†ä¸­</div>
                <div style="font-size: 1rem; color: #555; margin-bottom: 5px;">
                    æœ¬æ—¥ã“ã“ã¾ã§: <strong>{consumed_mins} åˆ†</strong> æ¶ˆåŒ–æ¸ˆ
                </div>
                <div class="metric-value"><span style="font-size: 1.5rem; color: #6c757d;">æ®‹ã‚Š</span> {rem_avg} <span style="font-size: 2rem;">ã€œ</span> {rem_p80} <span style="font-size: 1.5rem;">åˆ†</span></div>
                <div style="font-size: 0.95rem; color: #6c757d; margin-top: 12px; font-weight: 500;">
                    â€» å¹³å‡å€¤({int(avg_focus_mins)}åˆ†) ã€œ å¥½èª¿æ™‚({int(focus_p80)}åˆ†) ã®äºˆæ¸¬ãƒ¬ãƒ³ã‚¸
                </div>
            </div>
            """, unsafe_allow_html=True)
            
        with col2:
            st.markdown(f"""
            <div class="window-box">
                <div class="metric-title">ğŸ•’ ä»Šæ—¥ã®å‹è² æ  (Deep Work Window)</div>
                <div class="window-time">{window_text}</div>
                <div style="color: #555; margin-top: 10px;">ğŸ‘‰ {window_desc}</div>
            </div>
            """, unsafe_allow_html=True)
            
        if fatigue_risk:
            st.error("âš ï¸ **ç–²åŠ´ã‚¢ãƒ©ãƒ¼ãƒˆ**: ç¾åœ¨ç–²åŠ´ãŒè“„ç©ã—ã¦ã„ã‚‹ã‹ã€äºˆå®šãŒéå¯†ã§ã™ã€‚10åˆ†ç¨‹åº¦ã®å®Œå…¨ãªä¼‘æ¯ã‚’ã¨ã‚‹ã‹ã€é‡è¦ãªæ„æ€æ±ºå®šã‚’å¾Œå›ã—ã«ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
        else:
            st.success("âœ¨ **ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³è‰¯å¥½**: ç¾åœ¨ã€é›†ä¸­ã‚’é˜»å®³ã™ã‚‹å¤§ããªãƒã‚¤ã‚ºã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

        st.markdown("---")
        st.markdown("### ğŸ”® ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ (äº‹å‰äºˆæ¸¬)")
        st.write("ã€Œä»Šã‹ã‚‰ã©ã†è¡Œå‹•ã‚’å¤‰ãˆã‚Œã°ã€ã©ã‚Œãã‚‰ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå›å¾©ã™ã‚‹ã‹ï¼Ÿã€ã‚’AIãŒäº‹å‰è¨ˆç®—ã—ã¾ã—ãŸã€‚")
        
        def simulate_battery_gain(mod_dict):
            sim_data = target_data[feature_cols].copy()
            for k, v in mod_dict.items():
                if k in sim_data.columns: sim_data[k] = v
            sim_proba = model.predict_proba(sim_data)[0, 1]
            prob_diff = sim_proba - current_proba
            gain = int(prob_diff * avg_focus_mins * 1.5)
            return gain

        sim_walk = simulate_battery_gain({'çŸ­æ™‚é–“æ­©è¡Œ': 1.0, 'çŸ­æ™‚é–“æ­©è¡Œ_å‰': 1.0, '1åˆ†é–“æ­©æ•°': 1000})
        sim_rest = simulate_battery_gain({'ä¼‘æ†©åˆ¤å®š': 1.0, 'ä¼‘æ†©åˆ¤å®š_å‰': 1.0, 'time_since_prev_event_min': 30})
        sim_skip = simulate_battery_gain({'is_meeting': 0.0, 'has_schedule': 0.0, 'schedule_density_2h': max(0, target_data['schedule_density_2h'].values[0] - 0.25)})

        sim_col1, sim_col2, sim_col3 = st.columns(3)
        
        with sim_col1:
            st.info(f"**ğŸš¶ ä»Šã‹ã‚‰15åˆ†æ­©ã**\n\näºˆæ¸¬: ãƒãƒƒãƒ†ãƒªãƒ¼ **{'+' + str(sim_walk) if sim_walk > 0 else sim_walk} åˆ†**")
        with sim_col2:
            st.info(f"**â˜• äºˆå®šã®å‰ã«ä¼‘æ†©ã‚’ã¨ã‚‹**\n\näºˆæ¸¬: ãƒãƒƒãƒ†ãƒªãƒ¼ **{'+' + str(sim_rest) if sim_rest > 0 else sim_rest} åˆ†**")
        with sim_col3:
            st.info(f"**ğŸš« ç›´è¿‘ã®ä¼šè­°ã‚’1ã¤æ¸›ã‚‰ã™**\n\näºˆæ¸¬: ãƒãƒƒãƒ†ãƒªãƒ¼ **{'+' + str(sim_skip) if sim_skip > 0 else sim_skip} åˆ†**")

    # ==========================================
    # Tab 2: Weekly Report
    # ==========================================
    with tab_weekly:
        st.markdown("## é€±æœ«ã®æŒ¯ã‚Šè¿”ã‚Šã¨åˆ†æ (Weekly Report)")
        
        # --- ãƒã‚¤ãƒ«ãƒ¼ãƒ«ã®æ–‡ç« åŒ– ---
        st.markdown("#### ğŸ’¡ AIãŒè¦‹ã¤ã‘ãŸã€Œã‚ãªãŸå°‚ç”¨ã®é›†ä¸­ãƒ«ãƒ¼ãƒ«ã€")
        action_cols = [c for c in ['ä¼‘æ†©åˆ¤å®š', 'çŸ­æ™‚é–“æ­©è¡Œ', 'is_meeting', 'schedule_density_2h'] if c in df_imp.columns]
        if len(action_cols) > 0 and len(df_imp) > 10:
            reg_df = df_imp.dropna(subset=action_cols + [target_col])
            X_rule = reg_df[action_cols]
            y_rule = reg_df[target_col]
            
            tree_model = DecisionTreeRegressor(max_depth=2, min_samples_leaf=10, random_state=42)
            tree_model.fit(X_rule, y_rule)
            
            feat_names = []
            is_bool = []
            for col in action_cols:
                is_bool.append(reg_df[col].dropna().nunique() <= 2)
                if col == 'is_meeting': feat_names.append("ä¼šè­°ä¸­")
                elif col == 'schedule_density_2h': feat_names.append("äºˆå®šå¯†åº¦")
                else: feat_names.append(jp_feat_name(col))
                
            tree_rules = extract_rules(tree_model, feat_names, is_bool)
            valid_rules = [r for r in tree_rules if r[2] >= 5]
            if not valid_rules: valid_rules = tree_rules
            valid_rules.sort(key=lambda x: x[1], reverse=True)
            
            # è‰¯ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å±é™ºãªãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¸¡æ–¹ã‚’æŠ½å‡º
            positive_rule = None
            overwork_rule = None
            
            for rule_text, val, samples in valid_rules:
                display_prob = val * 100
                conditions = rule_text.split(" ï¼‹ ")
                cond_texts = [c.replace("ã€", "").replace("ã€‘", "") for c in conditions]
                
                has_positive_action = any(
                    ("ä¼‘æ†©" in c and ("ã‚ã‚Š" in c or "é«˜ã„" in c)) or
                    ("æ­©è¡Œ" in c and ("ã‚ã‚Š" in c or "é«˜ã„" in c))
                    for c in cond_texts
                )
                is_overwork = any(
                    ("äºˆå®šå¯†åº¦" in c and "é«˜ã„" in c) or
                    ("ä¼šè­°" in c and "ã‚ã‚Š" in c)
                    for c in cond_texts
                ) and not has_positive_action
                
                if has_positive_action and not positive_rule:
                    positive_rule = (cond_texts, display_prob, samples)
                if is_overwork and not overwork_rule:
                    overwork_rule = (cond_texts, display_prob, samples)
                    
                if positive_rule and overwork_rule:
                    break
                    
            if positive_rule:
                cond_joined = " ã‹ã¤ ".join(positive_rule[0])
                st.info(f"ğŸ’¡ **ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã§é›†ä¸­ã‚’é«˜ã‚ã‚‹é»„é‡‘ãƒ‘ã‚¿ãƒ¼ãƒ³**\n\n**ã€Œ{cond_joined}ã€** ã®çŠ¶æ³ãŒæ•´ã£ãŸã¨ãã€ã‚ãªãŸãŒé›†ä¸­çŠ¶æ…‹ã«å…¥ã‚‹ç¢ºç‡ã¯ **{positive_rule[1]:.1f} %** ã¾ã§é«˜ã¾ã‚Šã¾ã™ã€‚\n\n*(éå»ã®å®Ÿç¸¾: {positive_rule[2]}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šç®—å‡º)*\n\nğŸ‘‰ **ã‚³ãƒ¼ãƒã‹ã‚‰ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹:**\nç´ æ™´ã‚‰ã—ã„å‚¾å‘ã§ã™ï¼æ„å›³çš„ãªãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥è¡Œå‹•ï¼ˆä¼‘æ†©ã‚„æ­©è¡Œï¼‰ãŒã€ç¢ºå®Ÿãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã«ç¹‹ãŒã£ã¦ã„ã¾ã™ã€‚å¼•ãç¶šãã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ„è­˜ã—ã¾ã—ã‚‡ã†ã€‚")
                
            if overwork_rule:
                cond_joined = " ã‹ã¤ ".join(overwork_rule[0])
                st.warning(f"ğŸ’¡ **è¿½ã„è¾¼ã¿å‹ã®é›†ä¸­ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆç‡ƒãˆå°½ãæ³¨æ„ï¼‰**\n\n**ã€Œ{cond_joined}ã€** ã®ã‚ˆã†ã«ã€äºˆå®šãŒè©°ã¾ã£ã¦ã„ã¦ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãŒãªã„åˆ‡ç¾½è©°ã¾ã£ãŸçŠ¶æ³ã§ã€é›†ä¸­ç¢ºç‡ãŒ **{overwork_rule[1]:.1f} %** ã¾ã§é«˜ã¾ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚\n\n*(éå»ã®å®Ÿç¸¾: {overwork_rule[2]}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šç®—å‡º)*\n\nğŸ‘‰ **ã‚³ãƒ¼ãƒã‹ã‚‰ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹:**\nç· ã‚åˆ‡ã‚ŠåŠ¹æœç­‰ã§ã‚¹ã‚³ã‚¢ã¯ä¸€æ™‚çš„ã«é«˜ã¾ã£ã¦ã„ã¾ã™ãŒã€ã“ã®çŠ¶æ…‹ã‚’ç¶šã‘ã‚‹ã¨æ€¥æ¿€ãªç–²åŠ´ï¼ˆãƒãƒƒãƒ†ãƒªãƒ¼åˆ‡ã‚Œï¼‰ã‚’æ‹›ãã¾ã™ã€‚æ„è­˜çš„ã«äºˆå®šã«éš™é–“ã‚’ä½œã‚Šã€çŸ­ã„æ­©è¡Œã‚„ä¼‘æ†©ã‚’æŒŸã‚€ã‚ˆã†ã«è¡Œå‹•ã‚’å¤‰ãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                
            if not positive_rule and not overwork_rule and valid_rules:
                rule_text, val, samples = valid_rules[0]
                display_prob = val * 100
                conditions = rule_text.split(" ï¼‹ ")
                cond_texts = [c.replace("ã€", "").replace("ã€‘", "") for c in conditions]
                cond_joined = " ã‹ã¤ ".join(cond_texts)
                st.info(f"ğŸ’¡ **ã‚ãªãŸå°‚ç”¨ã®ã€Œé›†ä¸­ãƒ¢ãƒ¼ãƒ‰ã€ç™ºå‹•æ¡ä»¶**\n\n**ã€Œ{cond_joined}ã€** ã®çŠ¶æ³ãŒæ•´ã£ãŸã¨ãã€ã‚ãªãŸãŒé›†ä¸­çŠ¶æ…‹ã«å…¥ã‚‹ç¢ºç‡ã¯ **{display_prob:.1f} %** ã¾ã§é«˜ã¾ã‚Šã¾ã™ã€‚\n\n*(éå»ã®å®Ÿç¸¾: {samples}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šç®—å‡º)*")

        st.markdown("---")
        st.markdown("#### ğŸ“… ä»Šé€±ã®æ¨ç§»")
        
        week_start = (current_time - pd.to_timedelta(current_time.dayofweek, unit='d')).date()
        week_data_raw = df_ts_min[df_ts_min.index.date >= week_start].copy()
        week_data = week_data_raw[week_data_raw.index.dayofweek.isin(selected_dow_indices)]
        week_data = week_data[(week_data.index.hour >= time_range[0]) & (week_data.index.hour <= time_range[1])]
        
        if not week_data.empty and 'é›†ä¸­åˆ¤å®š' in week_data.columns:
            df_w_1t = week_data[['é›†ä¸­åˆ¤å®š']].resample('1T').mean()
            df_w_1t['é›†ä¸­ãƒ•ãƒ©ã‚°'] = (df_w_1t['é›†ä¸­åˆ¤å®š'] >= 0.5).astype(int)
            df_w_hourly = df_w_1t.resample('1H').sum()
            df_w_hourly['hour'] = df_w_hourly.index.hour
            df_w_hourly['dow'] = df_w_hourly.index.dayofweek
            
            # --- æ›œæ—¥åˆ¥ãƒ»æ™‚é–“å¸¯åˆ¥ã‚°ãƒ©ãƒ• ---
            col_w1, col_w2 = st.columns(2)
            with col_w1:
                dow_sum = df_w_hourly.groupby('dow')['é›†ä¸­ãƒ•ãƒ©ã‚°'].sum().reindex(selected_dow_indices, fill_value=0)
                fig_dow = px.bar(x=[dow_options[i] for i in selected_dow_indices], y=dow_sum.values, labels={'x': 'æ›œæ—¥', 'y': 'é›†ä¸­æ™‚é–“ (åˆ†)'}, title="æ›œæ—¥åˆ¥ã®é›†ä¸­æ™‚é–“")
                fig_dow.update_traces(marker_color='#1976d2')
                st.plotly_chart(fig_dow, use_container_width=True)
                
            with col_w2:
                target_hours_list = list(range(time_range[0], time_range[1] + 1))
                hour_sum = df_w_hourly.groupby('hour')['é›†ä¸­ãƒ•ãƒ©ã‚°'].sum().reindex(target_hours_list, fill_value=0)
                fig_hour = px.bar(x=[f"{h}:00" for h in target_hours_list], y=hour_sum.values, labels={'x': 'æ™‚é–“å¸¯', 'y': 'é›†ä¸­æ™‚é–“ (åˆ†)'}, title="æ™‚é–“å¸¯åˆ¥ã®é›†ä¸­æ™‚é–“")
                fig_hour.update_traces(marker_color='#1976d2')
                st.plotly_chart(fig_hour, use_container_width=True)

            # --- ã‚¦ã‚£ãƒ¼ã‚¯ãƒªãƒ¼ãƒ»ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ«ã‚°ãƒ©ãƒ• ---
            st.markdown("##### ğŸŒŠ æ—¥åˆ¥ã®ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ«ã‚°ãƒ©ãƒ• (CVRRã®æ³¢)")
            st.caption("â€» ä¸Šä¸‹ã®é¢ãŒãƒãƒ©ãƒ³ã‚¹è‰¯ãè¦‹ãˆã‚‹ã‚ˆã†ã€åŸºæº–å€¤(ã‚°ãƒ¬ãƒ¼ç‚¹ç·š)ã¯ã€Œä»Šé€±ã®å¹³å‡å€¤ã€ã«åˆã‚ã›ã¦è‡ªå‹•èª¿æ•´ã•ã‚Œã¦ã„ã¾ã™ã€‚æ¥µç«¯ã«ä½ã„å€¤ã¯ã‚°ãƒ©ãƒ•ä¸‹éƒ¨ã§çœç•¥ã—ã¦è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
            week_dates = [(week_start + datetime.timedelta(days=i)) for i in range(7)]
            target_dates = [d for d in week_dates if d.weekday() in selected_dow_indices]
            
            base_val = week_data['CVRR_SCORE_NEW'].mean() if 'CVRR_SCORE_NEW' in week_data.columns else 50.0
            if pd.isna(base_val): base_val = 50.0
            
            if not week_data.empty and 'CVRR_SCORE_NEW' in week_data.columns:
                week_max = week_data['CVRR_SCORE_NEW'].max()
                amp = week_max - base_val
                if amp < 10: amp = 10
                y_max_global = base_val + (amp * 1.2)
                y_min_global = base_val - (amp * 1.5)
            else:
                y_max_global, y_min_global = 100, 0
            
            for i in range(0, len(target_dates), 2):
                cols = st.columns(2)
                for j in range(2):
                    if i + j < len(target_dates):
                        t_date = target_dates[i+j]
                        dow_str = dow_options[t_date.weekday()]
                        with cols[j]:
                            df_day = df_ts_min[df_ts_min.index.date == t_date].copy()
                            df_day = df_day[(df_day.index.hour >= time_range[0]) & (df_day.index.hour <= time_range[1])]
                            if 'CVRR_SCORE_NEW' in df_day.columns and not df_day.empty and not df_day['CVRR_SCORE_NEW'].isna().all():
                                fig_d = go.Figure()
                                fig_d.add_trace(go.Scatter(x=df_day.index, y=[base_val]*len(df_day), mode='lines', line=dict(color='gray', width=1, dash='dash'), hoverinfo='skip'))
                                y_up = np.where(df_day['CVRR_SCORE_NEW'] >= base_val, df_day['CVRR_SCORE_NEW'], base_val)
                                fig_d.add_trace(go.Scatter(x=df_day.index, y=y_up, fill='tonexty', fillcolor='rgba(54, 162, 235, 0.5)', mode='lines', line=dict(width=0), hoverinfo='skip'))
                                fig_d.add_trace(go.Scatter(x=df_day.index, y=[base_val]*len(df_day), mode='lines', line=dict(width=0), hoverinfo='skip'))
                                y_down = np.where(df_day['CVRR_SCORE_NEW'] <= base_val, df_day['CVRR_SCORE_NEW'], base_val)
                                fig_d.add_trace(go.Scatter(x=df_day.index, y=y_down, fill='tonexty', fillcolor='rgba(255, 159, 64, 0.5)', mode='lines', line=dict(width=0), hoverinfo='skip'))
                                fig_d.add_trace(go.Scatter(x=df_day.index, y=df_day['CVRR_SCORE_NEW'], mode='lines', line=dict(color='#333333', width=2), hovertemplate="%{x|%H:%M}<br>ï½½ï½ºï½±: %{y:.1f}<extra></extra>"))
                                fig_d.update_layout(title=f"{t_date.strftime('%m/%d')} ({dow_str})", height=250, hovermode="x unified", plot_bgcolor='rgba(0,0,0,0)', margin=dict(l=20, r=20, t=30, b=20), showlegend=False)
                                fig_d.update_xaxes(showgrid=True, gridcolor='lightgray')
                                fig_d.update_yaxes(showgrid=True, gridcolor='lightgray', title="CVRR", range=[y_min_global, y_max_global])
                                st.plotly_chart(fig_d, use_container_width=True)
                            else:
                                st.markdown(f"**{t_date.strftime('%m/%d')} ({dow_str})**")
                                st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")

        # --- Gemini AIãƒ¬ãƒãƒ¼ãƒˆ ---
        if api_key:
            st.markdown("---")
            st.markdown("#### ğŸ¤– å°‚å±AIã‚³ãƒ¼ãƒã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
            with st.spinner("ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­..."):
                try:
                    genai.configure(api_key=api_key)
                    model_llm = genai.GenerativeModel('gemini-2.5-flash')
                    prompt = f"""
                    ã‚ãªãŸã¯ãƒ—ãƒ­ã®ç”Ÿç”£æ€§ã‚³ãƒ¼ãƒã§ã™ã€‚ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä»Šé€±ã®åƒãæ–¹ã‚’æŒ¯ã‚Šè¿”ã‚Šã€æ¥é€±ã«å‘ã‘ãŸã€Œæ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ã‚’3ã¤ææ¡ˆã—ã¦ãã ã•ã„ã€‚
                    ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¹³å‡é›†ä¸­ãƒãƒƒãƒ†ãƒªãƒ¼æ®‹é‡åŸºæº–: {int(avg_focus_mins)}åˆ†
                    ãƒ»æœ€è¿‘ã®é›†ä¸­ã‚¹ã‚³ã‚¢å¹³å‡: {week_data['CVRR_SCORE_NEW'].mean() if not week_data.empty and 'CVRR_SCORE_NEW' in week_data.columns else 'ä¸æ˜'}
                    ãƒ»ç¾åœ¨ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³: {'ç–²åŠ´ãƒªã‚¹ã‚¯ã‚ã‚Š' if fatigue_risk else 'è‰¯å¥½'}
                    å‡ºåŠ›å½¢å¼:
                    1. ä»Šé€±ã®ç·è©•ï¼ˆ1ã€œ2è¡Œï¼‰
                    2. æ¥é€±ã™ãã§ãã‚‹æ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆç®‡æ¡æ›¸ãã§3ã¤ã€å…·ä½“çš„ã«ï¼‰
                    """
                    resp = model_llm.generate_content(prompt)
                    st.success(resp.text)
                except Exception as e:
                    st.error(f"Gemini APIã‚¨ãƒ©ãƒ¼: {e}")

    # ==========================================
    # Tab 3: My Spec
    # ==========================================
    with tab_spec:
        st.markdown("## ğŸ‘¤ ã‚ãªãŸã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«ç‰¹æ€§ (My Spec)")
        st.write("éå»ã®ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ã‚ãªãŸå›ºæœ‰ã®é›†ä¸­ã¨ç–²åŠ´ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºã—ãŸã€Œã‚ãªãŸã®å–æ‰±èª¬æ˜æ›¸ã€ã§ã™ã€‚")
        
        df_insight = df_imp.copy()
        df_insight = df_insight[df_insight.index.dayofweek.isin(selected_dow_indices)]
        df_insight = df_insight[(df_insight.index.hour >= time_range[0]) & (df_insight.index.hour <= time_range[1])]

        target_hours_list = list(range(time_range[0], time_range[1] + 1))

        # --- å…¨æœŸé–“ã®ç‰¹æ€§ãƒ‡ãƒ¼ã‚¿ç®—å‡º (ã‚¿ã‚¤ãƒ—è¨ºæ–­ç”¨) ---
        focus_type_name = "ãƒ‡ãƒ¼ã‚¿ä¸è¶³"
        focus_type_desc = "ç‰¹å¾´ã‚’åˆ¤å®šã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒè¶³ã‚Šã¾ã›ã‚“ã€‚"
        hour_avg = pd.Series(dtype=float)
        dow_avg = pd.Series(dtype=float)

        if 'é›†ä¸­åˆ¤å®š' in df_insight.columns:
            df_ins_1t = df_insight[['é›†ä¸­åˆ¤å®š']].resample('1T').mean().ffill(limit=5)
            df_ins_1t['é›†ä¸­ãƒ•ãƒ©ã‚°'] = (df_ins_1t['é›†ä¸­åˆ¤å®š'] >= 0.5).astype(int)
            
            df_ins_hourly = df_ins_1t.resample('1H').sum()
            df_ins_hourly['date'] = df_ins_hourly.index.date
            df_ins_hourly['hour'] = df_ins_hourly.index.hour
            df_ins_hourly['dow'] = df_ins_hourly.index.dayofweek
            
            df_ins_hourly = df_ins_hourly[df_ins_hourly['dow'].isin(selected_dow_indices)]
            df_ins_hourly = df_ins_hourly[(df_ins_hourly['hour'] >= time_range[0]) & (df_ins_hourly['hour'] <= time_range[1])]
            
            total_days = df_ins_hourly['date'].nunique()
            if total_days > 0:
                hour_total = df_ins_hourly.groupby('hour')['é›†ä¸­ãƒ•ãƒ©ã‚°'].sum()
                hour_avg = (hour_total / total_days).reindex(target_hours_list, fill_value=0)
                
                dow_total = df_ins_hourly.groupby('dow')['é›†ä¸­ãƒ•ãƒ©ã‚°'].sum()
                days_per_dow = df_ins_hourly.groupby('dow')['date'].nunique()
                dow_avg = (dow_total / days_per_dow).reindex(selected_dow_indices, fill_value=0)
                
                am_hours = [h for h in target_hours_list if h < 12]
                pm1_hours = [h for h in target_hours_list if 12 <= h < 16]
                pm2_hours = [h for h in target_hours_list if 16 <= h]
                
                am_avg = hour_avg.loc[am_hours].mean() if am_hours else 0
                pm1_avg = hour_avg.loc[pm1_hours].mean() if pm1_hours else 0
                pm2_avg = hour_avg.loc[pm2_hours].mean() if pm2_hours else 0
                
                max_period = max(am_avg, pm1_avg, pm2_avg)
                if max_period > 0:
                    if max_period == am_avg:
                        focus_type_name = "ğŸŒ… åˆå‰é›†ä¸­å‹ (Morning Sprinter)"
                        focus_type_desc = "åˆå‰ä¸­ã«æœ€ã‚‚é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚é‡ã„ã‚¿ã‚¹ã‚¯ã¯æ˜¼ã¾ã§ã«ç‰‡ä»˜ã‘ã‚‹ã®ãŒãƒ™ã‚¹ãƒˆã§ã™ã€‚"
                    elif max_period == pm1_avg:
                        focus_type_name = "â˜€ï¸ åˆå¾Œã‚¹ã‚¿ãƒ¼ãƒˆå‹ (Afternoon Engine)"
                        focus_type_desc = "æ˜¼é£Ÿå¾Œã‹ã‚‰å¤•æ–¹ã«ã‹ã‘ã¦ã‚¨ãƒ³ã‚¸ãƒ³ãŒã‹ã‹ã‚‹ã‚¿ã‚¤ãƒ—ã§ã™ã€‚åˆå¾Œã«å‹è² ã‚¿ã‚¹ã‚¯ã‚’é…ç½®ã—ã¾ã—ã‚‡ã†ã€‚"
                    else:
                        focus_type_name = "ğŸŒ† å¤•æ–¹è¿½ã„è¾¼ã¿å‹ (Evening Closer)"
                        focus_type_desc = "å¤•æ–¹ä»¥é™ã«é›†ä¸­åŠ›ãŒé«˜ã¾ã‚‹ã‚¿ã‚¤ãƒ—ã§ã™ã€‚çµ‚æ¥­å‰ã®è¿½ã„è¾¼ã¿ãŒå¾—æ„ã§ã™ãŒã€ã‚ªãƒ¼ãƒãƒ¼ãƒ¯ãƒ¼ã‚¯ã«æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚"
                        
                    mean_val = hour_avg.mean()
                    cv = hour_avg.std() / mean_val if mean_val > 0 else 0
                    if cv > 0.4:
                        focus_type_name += " / ğŸŒŠ æ³¢å‹ã‚¹ãƒ—ãƒªãƒ³ã‚¿ãƒ¼"
                        focus_type_desc += " é›†ä¸­ã™ã‚‹æ™‚é–“ã¨ã—ãªã„æ™‚é–“ã®ãƒ¡ãƒªãƒãƒªãŒéå¸¸ã«å¼·ã„ãŸã‚ã€æ³¢ã«ä¹—ã‚Œã‚‹æ™‚é–“ã‚’é€ƒã•ãªã„ã“ã¨ãŒé‡è¦ã§ã™ã€‚"
                    else:
                        focus_type_name += " / ğŸ¢ å®‰å®šæŒç¶šå‹"
                        focus_type_desc += " 1æ—¥ã‚’é€šã—ã¦å®‰å®šã—ã¦é›†ä¸­ã‚’ä¿ã¤ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã¾ã‚ãªä¼‘æ†©ã§ã‚¹ã‚¿ãƒŸãƒŠã‚’ç¶­æŒã—ã¾ã—ã‚‡ã†ã€‚"

        if 'é›†ä¸­åˆ¤å®š' in df_insight.columns: df_insight['focus_start'] = (df_insight['é›†ä¸­åˆ¤å®š'] >= 0.5) & (df_insight['é›†ä¸­åˆ¤å®š'].shift(1) < 0.5)
        if 'ç–²åŠ´åˆ¤å®š' in df_insight.columns: df_insight['fatigue_start'] = (df_insight['ç–²åŠ´åˆ¤å®š'] >= 0.5) & (df_insight['ç–²åŠ´åˆ¤å®š'].shift(1) < 0.5)

        def get_peak_time(metric_col):
            if metric_col not in df_insight.columns: return "ä¸æ˜", "ä¸æ˜"
            pivot_df = df_insight.pivot_table(values=metric_col, index=df_insight.index.hour, columns=df_insight.index.dayofweek, aggfunc='mean')
            daytime_pivot = pivot_df.loc[time_range[0]:time_range[1], selected_dow_indices]
            if not daytime_pivot.isna().all().all():
                best_hour, best_dow = daytime_pivot.stack().idxmax()
                return dow_options[int(best_dow)], str(int(best_hour))
            return "ä¸æ˜", "ä¸æ˜"

        f_dow, f_hour = get_peak_time('é›†ä¸­åˆ¤å®š')
        fat_dow, fat_hour = get_peak_time('ç–²åŠ´åˆ¤å®š')

        avg_focus_duration_str, daily_focus_count_str, daily_total_focus_time_str = "ä¸æ˜", "ä¸æ˜", "ä¸æ˜"
        
        if 'é›†ä¸­åˆ¤å®š' in df_ts_min.columns:
            df_1min = df_ts_min[['é›†ä¸­åˆ¤å®š']].resample('1T').mean().ffill(limit=5)
            df_1min = df_1min[df_1min.index.dayofweek.isin(selected_dow_indices)]
            df_1min = df_1min[(df_1min.index.hour >= time_range[0]) & (df_1min.index.hour <= time_range[1])]
            
            focus_mask = df_1min['é›†ä¸­åˆ¤å®š'] >= 0.5
            focus_blocks = focus_mask.groupby((focus_mask != focus_mask.shift()).cumsum())
            focus_durations = focus_blocks.sum()[focus_blocks.sum() > 0]
            
            if not focus_durations.empty:
                avg_focus_duration_str = f"{focus_durations.mean():.0f}"
                num_days = df_1min.index.normalize().nunique()
                daily_focus_count_str = f"{(len(focus_durations) / num_days if num_days > 0 else 0):.1f}"
                daily_total_focus_time_str = f"{(focus_mask.sum() / num_days if num_days > 0 else 0):.0f}"

        focus_actions = []
        if '1åˆ†é–“æ­©æ•°' in df_insight.columns and 'focus_start' in df_insight.columns:
            walk_before = df_insight['1åˆ†é–“æ­©æ•°'].shift(1)[df_insight['focus_start']].dropna()
            avg_walk = df_insight['1åˆ†é–“æ­©æ•°'].mean()
            if not walk_before.empty and avg_walk > 0:
                if walk_before.mean() > avg_walk * 1.2: focus_actions.append("äº‹å‰ã«ä½“ã‚’å‹•ã‹ã™ã“ã¨ï¼ˆå°‘ã—æ­©ããªã©ï¼‰")
                elif walk_before.mean() < avg_walk * 0.8: focus_actions.append("äº‹å‰ã«é™ã‹ãªç’°å¢ƒã§è½ã¡ç€ã„ã¦éã”ã™ã“ã¨")

        if 'ä¼‘æ†©åˆ¤å®š' in df_insight.columns and 'focus_start' in df_insight.columns:
            rest_before = df_insight['ä¼‘æ†©åˆ¤å®š'].shift(1)[df_insight['focus_start']].dropna()
            if not rest_before.empty and df_insight['ä¼‘æ†©åˆ¤å®š'].mean() > 0:
                if rest_before.mean() > df_insight['ä¼‘æ†©åˆ¤å®š'].mean() * 1.2: focus_actions.append("äº‹å‰ã«ã—ã£ã‹ã‚Šä¼‘æ†©ã‚’ã¨ã‚‹ã“ã¨")

        focus_actions_str = "ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ç‰¹å®šã§ãã¾ã›ã‚“" if not focus_actions else "ã€".join(focus_actions)

        fatigue_actions = []
        if 'ç–²åŠ´åˆ¤å®š' in df_insight.columns and 'has_schedule' in df_insight.columns:
            sched_mask = df_insight['has_schedule'] >= 0.5
            sched_blocks = (sched_mask != sched_mask.shift()).cumsum()
            fatigue_diffs = []
            for _, group in df_insight[sched_mask].groupby(sched_blocks):
                if len(group) > 1:
                    dh = len(group) * (freq_td.total_seconds() / 3600)
                    if dh > 0: fatigue_diffs.append((group['ç–²åŠ´åˆ¤å®š'].iloc[-1] - group['ç–²åŠ´åˆ¤å®š'].iloc[0]) / dh)
            if fatigue_diffs and np.mean(fatigue_diffs) > 0: fatigue_actions.append("1æ™‚é–“ä»¥ä¸Šã®äºˆå®šã‚’ã“ãªã™ã“ã¨")

        if 'fatigue_start' in df_insight.columns and 'focus_start' in df_insight.columns:
            fat_times, foc_times = df_insight[df_insight['fatigue_start']].index, df_insight[df_insight['focus_start']].index
            rec_c, rec_s = [], []
            for ft in fat_times:
                ff = foc_times[foc_times > ft]
                if len(ff) > 0 and ff[0].date() == ft.date() and 'consecutive_schedules' in df_insight.columns:
                    if df_insight.loc[ft, 'consecutive_schedules'] >= 2: rec_c.append(1)
                    else: rec_s.append(1)
            if rec_c and rec_s and (np.mean(rec_c) - np.mean(rec_s)) > 0: fatigue_actions.append("äºˆå®šã‚’é€£ç¶šã—ã¦å…¥ã‚Œã‚‹ã“ã¨")

        fatigue_actions_str = "ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ç‰¹å®šã§ãã¾ã›ã‚“" if not fatigue_actions else "ã€".join(fatigue_actions)

        st.markdown(f"""
        <div style="background-color: #f8f9fa; padding: 20px; border-radius: 10px; border-left: 5px solid #28a745; margin-bottom: 20px;">
            <h4 style="margin-top: 0; color: #333;">ğŸ¯ ã‚ãªãŸã®é›†ä¸­ç‰¹æ€§</h4>
            <ul style="font-size: 1.1rem; color: #555;">
                <li><strong>é›†ä¸­ã‚¿ã‚¤ãƒ—ï¼š <span style="color:#28a745;">{focus_type_name}</span></strong><br>
                    <span style="font-size: 0.95rem; color: #777;">{focus_type_desc}</span></li>
                <li style="margin-top: 10px;"><strong>{f_dow}æ›œæ—¥ã®{f_hour}æ™‚å°</strong> ã«æœ€ã‚‚é›†ä¸­ã—ã‚„ã™ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚</li>
                <li>å¹³å‡é›†ä¸­æŒç¶šæ™‚é–“ã¯ <strong>{avg_focus_duration_str}åˆ†</strong> ã§ã™ã€‚</li>
                <li>1æ—¥ã®å¹³å‡é›†ä¸­æ™‚é–“ã¯ <strong>{daily_total_focus_time_str}åˆ†</strong> ã§ã™ã€‚</li>
                <li>1æ—¥ã«å¹³å‡ <strong>{daily_focus_count_str}å›</strong> ã®é›†ä¸­ã‚µã‚¤ã‚¯ãƒ«ã‚’ç¹°ã‚Šè¿”ã—ã¦ã„ã¾ã™ã€‚</li>
                <li>é›†ä¸­ã«å…¥ã‚Šã‚„ã™ã„è¡Œå‹•ï¼š <strong>{focus_actions_str}</strong></li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

        st.markdown(f"""
        <div style="background-color: #f8f9fa; padding: 20px; border-radius: 10px; border-left: 5px solid #dc3545; margin-bottom: 20px;">
            <h4 style="margin-top: 0; color: #333;">ğŸ”‹ ã‚ãªãŸã®ç–²åŠ´ç‰¹æ€§</h4>
            <ul style="font-size: 1.1rem; color: #555;">
                <li><strong>{fat_dow}æ›œæ—¥ã®{fat_hour}æ™‚å°</strong> ã«æœ€ã‚‚ç–²åŠ´ã—ã‚„ã™ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚</li>
                <li>ç–²åŠ´ã—ã‚„ã™ã„è¡Œå‹•ï¼š <strong>{fatigue_actions_str}</strong></li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # --- å…¨æœŸé–“ã®æ£’ã‚°ãƒ©ãƒ• ---
        st.markdown("---")
        st.markdown("#### ğŸ“Š å…¨æœŸé–“ã®é›†ä¸­å‚¾å‘ (æ›œæ—¥ãƒ»æ™‚é–“å¸¯åˆ¥)")
        
        if not hour_avg.empty and not dow_avg.empty:
            col_s1, col_s2 = st.columns(2)
            with col_s1:
                fig_dow_all = px.bar(x=[dow_options[i] for i in selected_dow_indices], y=dow_avg.values, labels={'x': 'æ›œæ—¥', 'y': '1æ—¥å¹³å‡ é›†ä¸­æ™‚é–“ (åˆ†)'}, title="æ›œæ—¥åˆ¥ã®å¹³å‡é›†ä¸­æ™‚é–“")
                fig_dow_all.update_traces(marker_color='#28a745')
                st.plotly_chart(fig_dow_all, use_container_width=True)
            with col_s2:
                fig_hour_all = px.bar(x=[f"{h}:00" for h in target_hours_list], y=hour_avg.values, labels={'x': 'æ™‚é–“å¸¯', 'y': '1æ—¥å¹³å‡ é›†ä¸­æ™‚é–“ (åˆ†)'}, title="æ™‚é–“å¸¯åˆ¥ã®å¹³å‡é›†ä¸­æ™‚é–“")
                fig_hour_all.update_traces(marker_color='#28a745')
                st.plotly_chart(fig_hour_all, use_container_width=True)
        else:
            st.info("ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ååˆ†ãªè¨˜éŒ²ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

        # --- ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— (å…¨æœŸé–“) ---
        st.markdown("##### ğŸ“ æ›œæ—¥Ã—æ™‚é–“å¸¯ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— (å…¨æœŸé–“)")
        col_hm1, col_hm2 = st.columns(2)
        def plot_overall_hm(metric_col, colorscale, title):
            if metric_col not in df_insight.columns: return None
            df_h = df_insight[[metric_col]].resample('1H').mean()
            df_h['hour'] = df_h.index.hour
            df_h['dow'] = df_h.index.dayofweek
            pivot = df_h.pivot_table(values=metric_col, index='hour', columns='dow', aggfunc='mean')
            heatmap_data = np.full((len(target_hours_list), len(selected_dow_indices)), np.nan)
            for i, h in enumerate(target_hours_list):
                for j, d in enumerate(selected_dow_indices):
                    if h in pivot.index and d in pivot.columns:
                        heatmap_data[i, j] = pivot.loc[h, d]
            fig = go.Figure(data=go.Heatmap(z=heatmap_data, x=[dow_options[d] for d in selected_dow_indices], y=[f"{h}:00" for h in target_hours_list], colorscale=colorscale, hoverongaps=False))
            fig.update_layout(title=title, yaxis_autorange='reversed', height=350, margin=dict(l=20, r=20, t=40, b=20))
            return fig
        
        with col_hm1:
            fig_hm_focus = plot_overall_hm('é›†ä¸­åˆ¤å®š', 'Blues', "é›†ä¸­ç¢ºç‡ (é’ã„ã»ã©é«˜ã„)")
            if fig_hm_focus: st.plotly_chart(fig_hm_focus, use_container_width=True)
        with col_hm2:
            if 'ç–²åŠ´åˆ¤å®š' in df_insight.columns:
                fig_hm_fat = plot_overall_hm('ç–²åŠ´åˆ¤å®š', 'Reds', "ç–²åŠ´ç¢ºç‡ (èµ¤ã„ã»ã©é«˜ã„)")
                if fig_hm_fat: st.plotly_chart(fig_hm_fat, use_container_width=True)