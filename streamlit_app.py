# -*- coding: utf-8 -*-
"""
Deep Work æœ€å¤§åŒ–ãƒ»é›†ä¸­æ³¢è§£æã‚¢ãƒ—ãƒª (Wave Dynamics + Fatigue & Arousal Layer)
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import lightgbm as lgb
from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, brier_score_loss
import scipy.signal as signal
import shap
import warnings
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import matplotlib as mpl
import matplotlib.font_manager as fm
import datetime
import math
import io

# --- Streamlit ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Deep Work Wave Dynamics", layout="wide", initial_sidebar_state="expanded")

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
font_path = Path(__file__).parent / "assets" / "fonts" / "NotoSansCJKjp-Regular.otf"
if font_path.exists():
    fm.fontManager.addfont(str(font_path))
    prop = fm.FontProperties(fname=str(font_path))
    mpl.rcParams["font.family"] = prop.get_name()

mpl.rcParams["axes.unicode_minus"] = False
warnings.filterwarnings('ignore')

# --- ã‚«ã‚¹ã‚¿ãƒ CSS ---
st.markdown("""
<style>
    .kpi-card { background-color: #ffffff; border-radius: 12px; padding: 24px; text-align: center; box-shadow: 0 4px 12px rgba(0,0,0,0.05); margin-bottom: 20px; border: 1px solid #f0f2f6; }
    .kpi-title { font-size: 1.1rem; color: #6c757d; margin-bottom: 8px; font-weight: 600; text-transform: uppercase; letter-spacing: 0.05em; }
    .kpi-value-main { font-size: 3.5rem; color: #1e293b; font-weight: 800; line-height: 1.1; margin-bottom: 5px; }
    .kpi-value-wave { font-size: 2.5rem; color: #2563eb; font-weight: 800; line-height: 1.2; margin-bottom: 5px; }
    .kpi-unit { font-size: 1.2rem; color: #64748b; font-weight: 500; }
    .kpi-sub { font-size: 1.1rem; color: #10b981; font-weight: bold; margin-top: 10px; }
    .kpi-sub.warning { color: #f59e0b; }
    .kpi-sub.alert { color: #ef4444; }
    .chance-box { background-color: #f0fdf4; border-left: 6px solid #10b981; padding: 20px; border-radius: 8px; margin-bottom: 20px; }
    .chance-time { font-size: 1.8rem; color: #047857; font-weight: 800; }
    .sim-box { background-color: #f8fafc; padding: 16px; border-radius: 8px; border: 1px dashed #cbd5e1; height: 100%; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# ğŸ›‘ A. ç–²åŠ´ãƒ»å›å¾©ãƒ¬ã‚¤ãƒ¤ãƒ¼ (1åˆ†ç²’åº¦)
# ==========================================
def compute_fatigue_features(df_1min, steps_col=None):
    df = df_1min.copy()
    
    # 1) ç–²åŠ´ã‚¹ã‚³ã‚¢ã®å®šç¾©
    has_rmssd = 'RMSSD_SCORE_NEW' in df.columns
    has_tp = 'TP_SCORE_NEW' in df.columns
    
    if has_rmssd and has_tp:
        df['fatigue_score'] = 0.6 * df['RMSSD_SCORE_NEW'] + 0.4 * df['TP_SCORE_NEW']
    elif has_rmssd:
        df['fatigue_score'] = df['RMSSD_SCORE_NEW']
    elif has_tp:
        df['fatigue_score'] = df['TP_SCORE_NEW']
    else:
        df['fatigue_score'] = 50.0  # fallback
        
    # å¹³æ»‘åŒ– (EWMA span=10)
    df['fatigue_smooth'] = df['fatigue_score'].ewm(span=10, min_periods=1).mean()
    
    # 2) ç–²åŠ´ã®ãƒ‰ãƒªãƒ•ãƒˆ (ç›´è¿‘60åˆ†ã®å‚¾ãè¿‘ä¼¼: FIRãƒ•ã‚£ãƒ«ã‚¿)
    # ç·šå½¢å›å¸°ã®å‚¾ãã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚é‡ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½¿ç”¨
    w60 = np.arange(60) - 29.5
    var_x = np.sum(w60**2)
    w60 = w60 / var_x if var_x > 0 else w60
    df['fatigue_drift_60m'] = df['fatigue_smooth'].rolling(60, min_periods=60).apply(lambda y: np.dot(w60, y), raw=True).fillna(0)
    
    # ãƒãƒ³ãƒ‰åˆ†é¡
    q33 = df['fatigue_smooth'].quantile(0.33) if not df['fatigue_smooth'].isna().all() else 33.0
    q66 = df['fatigue_smooth'].quantile(0.66) if not df['fatigue_smooth'].isna().all() else 66.0
    df['fatigue_level_band'] = np.where(df['fatigue_smooth'] >= q66, 'é«˜', np.where(df['fatigue_smooth'] <= q33, 'ä½', 'ä¸­'))
    
    # 3) å›å¾©ã®æ¨å®š (æ­©æ•°ãŒã‚ã‚‹å ´åˆ)
    if steps_col and steps_col in df.columns:
        df['rest_flag'] = np.where(df[steps_col] <= 5, 1, np.where(df[steps_col] >= 20, 0, np.nan))
        df['rest_flag'] = df['rest_flag'].ffill().fillna(0)
        
        # å®‰é™ãƒ–ãƒ­ãƒƒã‚¯ID
        rest_blocks = (df['rest_flag'] != df['rest_flag'].shift()).cumsum()
        df['rest_block_id'] = rest_blocks.where(df['rest_flag'] == 1, np.nan)
    else:
        df['rest_flag'] = np.nan
        df['rest_block_id'] = np.nan
        
    return df

def compute_morning_residual(df_1min, date_col='date', tp_col="TP_SCORE_NEW", rest_flag_col="rest_flag"):
    results = []
    df = df_1min.copy()
    if 'date' not in df.columns: df['date'] = df.index.date
    
    for d, group in df.groupby('date'):
        morning = group[(group.index.hour >= 0) & (group.index.hour < 12)]
        if morning.empty or rest_flag_col not in morning.columns:
            continue
            
        rest_blocks = morning[rest_flag_col] == 1
        blocks = rest_blocks.groupby((rest_blocks != rest_blocks.shift()).cumsum())
        
        target_block = None
        for _, b in blocks:
            if b.iloc[0] == True:
                if len(b) >= 60:
                    target_block = b
                    break
                elif len(b) >= 30 and target_block is None:
                    target_block = b # 60åˆ†ãŒãªã„å ´åˆã¯30åˆ†ã§å¦¥å”
                    
        if target_block is not None and tp_col in morning.columns:
            tp_median = morning.loc[target_block.index, tp_col].median()
            results.append({'date': d, 'morning_tp_median': tp_median, 'rest_duration': len(target_block)})
            
    res_df = pd.DataFrame(results)
    if not res_df.empty and 'morning_tp_median' in res_df.columns:
        median_all = res_df['morning_tp_median'].median()
        mad = (res_df['morning_tp_median'] - median_all).abs().median()
        if mad == 0: mad = 1.0
        res_df['morning_residual_z'] = 0.6745 * (res_df['morning_tp_median'] - median_all) / mad
        res_df['morning_residual_band'] = np.where(res_df['morning_residual_z'] >= 1.0, 'é«˜',
                                          np.where(res_df['morning_residual_z'] <= -1.0, 'ä½', 'ä¸­'))
    return res_df

# ==========================================
# ğŸ›‘ B. ä½è¦šé†’ãƒ¬ã‚¤ãƒ¤ãƒ¼ (1åˆ†ç²’åº¦)
# ==========================================
def compute_low_arousal(df_1min, pr_col="PR_SCORE_NEW", steps_col=None):
    df = df_1min.copy()
    if pr_col not in df.columns:
        df['low_arousal'] = 0.0
        df['low_arousal_band'] = 'ä½'
        df['low_arousal_rise_15m'] = 0.0
        return df
        
    # 5åˆ†çª“ã®å›å¸°å‚¾ã
    w5 = np.array([-2, -1, 0, 1, 2]) / 10.0
    slope = df[pr_col].rolling(5, min_periods=5).apply(lambda y: np.dot(w5, y), raw=True).fillna(0)
    
    eps = 0.02
    delta = np.maximum(0, -(slope + eps))
    
    alpha = 0.95
    k = 1.0
    
    low_arousal = np.zeros(len(df))
    dates = df.index.date
    steps = df[steps_col].values if steps_col and steps_col in df.columns else np.zeros(len(df))
    
    # æ¸›è¡°ç©åˆ†
    for i in range(1, len(df)):
        if dates[i] != dates[i-1]:
            low_arousal[i] = 0
        else:
            current_alpha = alpha
            if steps[i] >= 20:
                current_alpha = 0.80 # æ´»å‹•ä¸­ã¯æ¸›è¡°ã‚’æ—©ã‚ã‚‹
            low_arousal[i] = current_alpha * low_arousal[i-1] + k * delta.iloc[i]
            
    df['low_arousal'] = low_arousal
    
    q33 = df['low_arousal'].quantile(0.33) if df['low_arousal'].max() > 0 else 0
    q66 = df['low_arousal'].quantile(0.66) if df['low_arousal'].max() > 0 else 0
    df['low_arousal_band'] = np.where(df['low_arousal'] >= q66, 'é«˜', np.where(df['low_arousal'] <= q33, 'ä½', 'ä¸­'))
    
    df['low_arousal_rise_15m'] = df['low_arousal'] - df['low_arousal'].shift(15).fillna(0)
    
    return df

def summarize_daily_condition(df_1min):
    m_res = compute_morning_residual(df_1min)
    
    daily = []
    df = df_1min.copy()
    if 'date' not in df.columns: df['date'] = df.index.date
    
    for d, group in df.groupby('date'):
        daytime = group[(group.index.hour >= 9) & (group.index.hour <= 19)]
        fatigue_load = daytime['fatigue_score'].sum() if 'fatigue_score' in daytime.columns else 0
        
        recovery = 0.0
        if 'rest_block_id' in group.columns and 'fatigue_smooth' in group.columns:
            for _, b in group.groupby('rest_block_id'):
                diff = b['fatigue_smooth'].iloc[0] - b['fatigue_smooth'].iloc[-1]
                if diff > 0: recovery += diff
                
        la_peak_time = "ãªã—"
        if 'low_arousal' in group.columns and group['low_arousal'].max() > 0:
            peak_idx = group['low_arousal'].idxmax()
            la_peak_time = peak_idx.strftime('%H:%M')
            
        daily.append({
            'æ—¥ä»˜': d,
            'æ—¥ä¸­ç–²åŠ´è² è·': int(fatigue_load),
            'å®‰é™å›å¾©é‡': round(recovery, 1),
            'ä½è¦šé†’ãƒ”ãƒ¼ã‚¯': la_peak_time
        })
        
    df_daily = pd.DataFrame(daily)
    if not m_res.empty:
        df_daily = pd.merge(df_daily, m_res[['date', 'morning_residual_band']], left_on='æ—¥ä»˜', right_on='date', how='left')
        df_daily = df_daily.rename(columns={'morning_residual_band': 'æœã®æ®‹ç–²åŠ´ (å¯èƒ½æ€§)'}).drop(columns=['date'])
    else:
        df_daily['æœã®æ®‹ç–²åŠ´ (å¯èƒ½æ€§)'] = 'ä¸æ˜'
        
    # åˆ—é †èª¿æ•´
    cols = ['æ—¥ä»˜', 'æœã®æ®‹ç–²åŠ´ (å¯èƒ½æ€§)', 'æ—¥ä¸­ç–²åŠ´è² è·', 'å®‰é™å›å¾©é‡', 'ä½è¦šé†’ãƒ”ãƒ¼ã‚¯']
    return df_daily[[c for c in cols if c in df_daily.columns]]

# ==========================================
# ğŸŒŠ 1. æ³¢è§£æãƒ»ç‰¹å¾´é‡æŠ½å‡ºãƒ»Deep Workç”Ÿæˆ
# ==========================================
def make_wave_features(df_resampled, df_sched, freq_td):
    df_feat = df_resampled.copy()
    
    # 1ï¸âƒ£ çµ±åˆé›†ä¸­å¼·åº¦ã‚¹ã‚³ã‚¢ã®æ§‹ç¯‰
    focus_components = []
    if 'CVRR_SCORE_NEW' in df_feat.columns:
        focus_components.append(df_feat['CVRR_SCORE_NEW'])
    if 'RMSSD_SCORE_NEW' in df_feat.columns:
        focus_components.append(100 - df_feat['RMSSD_SCORE_NEW']) # ç–²åŠ´æŒ‡æ¨™ã‚’åè»¢
    if 'LFHF_SCORE_NEW' in df_feat.columns:
        focus_components.append(df_feat['LFHF_SCORE_NEW'])
        
    if focus_components:
        df_feat['focus_intensity'] = pd.concat(focus_components, axis=1).mean(axis=1)
    elif 'é›†ä¸­åˆ¤å®š' in df_feat.columns:
        df_feat['focus_intensity'] = df_feat['é›†ä¸­åˆ¤å®š'] * 100 
    else:
        df_feat['focus_intensity'] = 50.0
        
    win_size_5m = max(1, int(pd.Timedelta('5T') / freq_td))
    df_feat['focus_smooth'] = df_feat['focus_intensity'].rolling(window=win_size_5m, min_periods=1).mean()
    
    df_feat['focus_diff'] = df_feat['focus_smooth'].diff()
    df_feat['phase_num'] = np.where(df_feat['focus_diff'] > 0, 1, np.where(df_feat['focus_diff'] < 0, -1, 0))
    df_feat['phase_str'] = np.where(df_feat['phase_num'] > 0, 'ä¸Šæ˜‡å±€é¢ â†—', np.where(df_feat['phase_num'] < 0, 'ä¸‹é™å±€é¢ â†˜', 'åœæ»'))
    
    dist_steps = max(1, int(pd.Timedelta('15T') / freq_td))
    prominence = df_feat['focus_smooth'].std() * 0.2
    if pd.isna(prominence) or prominence == 0: prominence = 0.1
    
    fs_arr = df_feat['focus_smooth'].fillna(0).values
    peaks, _ = signal.find_peaks(fs_arr, distance=dist_steps, prominence=prominence)
    valleys, _ = signal.find_peaks(-fs_arr, distance=dist_steps, prominence=prominence)
    
    df_feat['is_peak'] = 0
    if len(peaks) > 0: df_feat.iloc[peaks, df_feat.columns.get_loc('is_peak')] = 1
    df_feat['is_valley'] = 0
    if len(valleys) > 0: df_feat.iloc[valleys, df_feat.columns.get_loc('is_valley')] = 1
    
    df_feat['last_peak_val'] = df_feat['focus_smooth'].where(df_feat['is_peak'] == 1).ffill()
    df_feat['last_valley_val'] = df_feat['focus_smooth'].where(df_feat['is_valley'] == 1).ffill()
    
    idx_series = pd.Series(df_feat.index, index=df_feat.index)
    df_feat['last_peak_time'] = idx_series.where(df_feat['is_peak'] == 1).ffill()
    
    df_feat['wave_amplitude'] = (df_feat['last_peak_val'] - df_feat['last_valley_val']).fillna(0)
    
    df_feat['prev_peak_time'] = df_feat['last_peak_time'].where(df_feat['is_peak']==1).shift(1).ffill()
    df_feat['wave_period_min'] = (df_feat['last_peak_time'] - df_feat['prev_peak_time']).dt.total_seconds() / 60
    df_feat['wave_period_min'] = df_feat['wave_period_min'].fillna(0)
    
    q70 = df_feat['focus_smooth'].quantile(0.70)
    if pd.isna(q70): q70 = 50.0
    df_feat['is_high_focus_wave'] = (df_feat['focus_smooth'] >= q70).astype(int)
    
    df_feat['has_schedule'] = 0
    df_feat['is_meeting'] = 0
    if df_sched is not None and not df_sched.empty:
        meeting_keywords = ['ä¼šè­°', 'æ‰“åˆã›', 'MTG', 'é¢è«‡', 'å•†è«‡']
        for _, row in df_sched.iterrows():
            mask = (df_feat.index < row['end_dt']) & ((df_feat.index + freq_td) > row['start_dt'])
            df_feat.loc[mask, 'has_schedule'] = 1
            if any(kw in str(row.get('ä»¶å', '')) for kw in meeting_keywords):
                df_feat.loc[mask, 'is_meeting'] = 1
                
    win_steps_2h = max(1, int(pd.Timedelta('2H') / freq_td))
    df_feat['schedule_density_2h'] = df_feat['has_schedule'].rolling(win_steps_2h, min_periods=1).mean().shift(1).fillna(0)
    
    df_feat['deep_work'] = ((df_feat['has_schedule'] == 0) & (df_feat['is_high_focus_wave'] == 1)).astype(int)
    
    dw_series = df_feat['deep_work']
    df_feat['dw_block_id'] = (dw_series != dw_series.shift()).cumsum()
    df_feat['dw_block_id'] = df_feat['dw_block_id'].where(dw_series == 1, np.nan)
    
    df_feat['hour'] = df_feat.index.hour
    df_feat['dayofweek'] = df_feat.index.dayofweek
    
    return df_feat, q70

def compute_personal_metrics(df_feat, freq_td, current_time):
    metrics = {}
    mins_per_step = freq_td.total_seconds() / 60
    df_feat['date'] = df_feat.index.date
    
    block_lengths = df_feat.groupby('dw_block_id').size() * mins_per_step
    metrics['avg_dw_duration'] = block_lengths.mean() if not block_lengths.empty else 0
    metrics['dw_loss_minutes_total'] = block_lengths[block_lengths < 30].sum() if not block_lengths.empty else 0
    
    valid_periods = df_feat['wave_period_min'][df_feat['wave_period_min'] > 0]
    metrics['avg_wave_period'] = valid_periods.median() if not valid_periods.empty else 18.0
    metrics['avg_wave_amplitude'] = df_feat['wave_amplitude'][df_feat['wave_amplitude'] > 0].mean()
    if pd.isna(metrics['avg_wave_amplitude']): metrics['avg_wave_amplitude'] = 10.0
    
    total_blank_steps = (df_feat['has_schedule'] == 0).sum()
    total_dw_steps = df_feat['deep_work'].sum()
    metrics['dw_rate'] = (total_dw_steps / total_blank_steps * 100) if total_blank_steps > 0 else 0
    
    past_28_days = current_time.date() - pd.Timedelta(days=28)
    df_past = df_feat[(df_feat['date'] >= past_28_days) & (df_feat['date'] < current_time.date())]
    df_past_weekday = df_past[df_past['dayofweek'] < 5]
    
    if not df_past_weekday.empty:
        past_daily_dw = df_past_weekday.groupby('date')['deep_work'].sum() * mins_per_step
        target_raw = past_daily_dw.mean() * 1.10
        metrics['target_dw_mins'] = int(round(target_raw / 5.0) * 5)
    else:
        metrics['target_dw_mins'] = 120
    if metrics['target_dw_mins'] == 0: metrics['target_dw_mins'] = 60
    
    today_data = df_feat[df_feat['date'] == current_time.date()]
    today_blank_steps = (today_data['has_schedule'] == 0).sum()
    today_dw_steps = today_data['deep_work'].sum()
    metrics['today_dw_mins'] = today_dw_steps * mins_per_step
    metrics['today_dw_rate'] = (today_dw_steps / today_blank_steps * 100) if today_blank_steps > 0 else 0
    
    today_blocks = today_data.groupby('dw_block_id').size() * mins_per_step
    metrics['today_dw_loss'] = today_blocks[today_blocks < 30].sum() if not today_blocks.empty else 0
    
    return metrics

def train_predict_classifier(df_feat, ahead_steps):
    df_feat['target_class'] = df_feat['is_high_focus_wave'].shift(-ahead_steps)

    feature_cols = ['hour', 'dayofweek', 'wave_amplitude', 'wave_period_min', 'phase_num', 'schedule_density_2h']
    for col in ['1åˆ†é–“æ­©æ•°', 'SkinTemp']:
        if col in df_feat.columns: feature_cols.append(col)
    
    df_model = df_feat.dropna(subset=['target_class'] + feature_cols).copy()
    if len(df_model) < 50:
        return None, None, {}, df_feat
        
    split_idx = int(len(df_model) * 0.8)
    train_df = df_model.iloc[:split_idx]
    test_df = df_model.iloc[split_idx:]
    
    X_train, y_train = train_df[feature_cols], train_df['target_class']
    X_test, y_test = test_df[feature_cols], test_df['target_class']
    
    if y_train.nunique() <= 1:
        return None, None, {}, df_feat
        
    model = lgb.LGBMClassifier(objective='binary', n_estimators=100, learning_rate=0.05, random_state=42, verbose=-1)
    model.fit(X_train, y_train)
    
    eval_metrics = {}
    if y_test.nunique() > 1:
        preds_proba = model.predict_proba(X_test)[:, 1]
        preds_bin = (preds_proba >= 0.5).astype(int)
        eval_metrics['ROC-AUC'] = roc_auc_score(y_test, preds_proba)
        eval_metrics['PR-AUC'] = average_precision_score(y_test, preds_proba)
        eval_metrics['F1 Score'] = f1_score(y_test, preds_bin)
        eval_metrics['Brier Score'] = brier_score_loss(y_test, preds_proba)
    
    return model, feature_cols, eval_metrics, df_model

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼UI ---
with st.sidebar:
    st.header("âš™ï¸ ãƒ‡ãƒ¼ã‚¿å…¥åŠ›")
    file_ts = st.file_uploader("1. ç”Ÿä½“ãƒ‡ãƒ¼ã‚¿ (CSV)", type=['csv'])
    file_sched = st.file_uploader("2. äºˆå®šè¡¨ãƒ‡ãƒ¼ã‚¿ (CSV) â€»ä»»æ„", type=['csv'])
    
    with st.expander("ğŸ›  æ³¢è§£æãƒ»è©³ç´°è¨­å®š (ç®¡ç†è€…ç”¨)"):
        RESAMPLE_FREQ = st.selectbox("åˆ†æå˜ä½ (æ³¢è§£åƒåº¦)", ['1T', '5T', '10T', '30T'], index=1)
        PREDICT_AHEAD_MINS = st.selectbox("äºˆæ¸¬å…ˆ (åˆ†)", [30, 60], index=0)
        TARGET_DATETIME_STR = st.text_input("äºˆæ¸¬åŸºæº–æ—¥æ™‚ (ç©ºæ¬„ã§æœ€æ–°)")
        time_range = st.slider("ã‚°ãƒ©ãƒ•è¡¨ç¤ºæ™‚é–“å¸¯", 0, 23, (9, 19))
        
    st.markdown("---")
    run_btn = st.button("ğŸš€ ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚’è§£æ", type="primary", use_container_width=True)

freq_td = pd.Timedelta(RESAMPLE_FREQ)
ahead_steps = max(1, int(pd.Timedelta(minutes=PREDICT_AHEAD_MINS) / freq_td))
TARGET_DATETIME = TARGET_DATETIME_STR if TARGET_DATETIME_STR.strip() != "" else None

# === ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===
if run_btn or file_ts is not None:
    if file_ts is None:
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œç”Ÿä½“ãƒ‡ãƒ¼ã‚¿ã€ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
        
    with st.spinner("AIãŒé›†ä¸­ãƒ»ç–²åŠ´ãƒ»è¦šé†’ã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’è§£æä¸­..."):
        # 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        df_ts_raw = pd.read_csv(io.BytesIO(file_ts.getvalue()), skiprows=2)
        df_ts_raw['timestamp_clean'] = df_ts_raw['timestamp'].astype(str).str.split(' GMT').str[0]
        df_ts_raw['datetime'] = pd.to_datetime(df_ts_raw['timestamp_clean'], errors='coerce')
        df_ts_raw = df_ts_raw.dropna(subset=['datetime']).set_index('datetime').sort_index()

        df_sched_raw = None
        if file_sched:
            df_sched_raw = pd.read_csv(io.BytesIO(file_sched.getvalue()))
            df_sched_raw = df_sched_raw[df_sched_raw['çµ‚æ—¥ã‚¤ãƒ™ãƒ³ãƒˆ'].astype(str).str.upper() != 'TRUE']
            df_sched_raw['start_dt'] = pd.to_datetime(df_sched_raw['é–‹å§‹æ—¥'].astype(str) + ' ' + df_sched_raw['é–‹å§‹æ™‚åˆ»'].astype(str), errors='coerce')
            df_sched_raw['end_dt']   = pd.to_datetime(df_sched_raw['çµ‚äº†æ—¥'].astype(str) + ' ' + df_sched_raw['çµ‚äº†æ™‚åˆ»'].astype(str), errors='coerce')
            df_sched_raw = df_sched_raw.dropna(subset=['start_dt', 'end_dt']).sort_values('start_dt')
            
        # 2. 1åˆ†ç²’åº¦ãƒ‡ãƒ¼ã‚¿ã¨ç–²åŠ´ãƒ»ä½è¦šé†’ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ä½œæˆ
        num_cols = df_ts_raw.select_dtypes(include=[np.number]).columns
        df_1min = df_ts_raw[num_cols].resample('1T').mean()
        if '1åˆ†é–“æ­©æ•°' in df_ts_raw.columns:
            df_1min['1åˆ†é–“æ­©æ•°'] = df_ts_raw['1åˆ†é–“æ­©æ•°'].resample('1T').sum()
        df_1min = df_1min.ffill(limit=5)
        
        steps_col_name = '1åˆ†é–“æ­©æ•°' if '1åˆ†é–“æ­©æ•°' in df_1min.columns else None
        df_1min = compute_fatigue_features(df_1min, steps_col=steps_col_name)
        df_1min = compute_low_arousal(df_1min, pr_col='PR_SCORE_NEW' if 'PR_SCORE_NEW' in df_1min.columns else None, steps_col=steps_col_name)

        # 3. é›†ä¸­æ³¢è§£æç”¨ã®ãƒªã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        df_resampled = df_ts_raw[num_cols].resample(RESAMPLE_FREQ).mean()
        if '1åˆ†é–“æ­©æ•°' in df_ts_raw.columns:
            df_resampled['1åˆ†é–“æ­©æ•°'] = df_ts_raw['1åˆ†é–“æ­©æ•°'].resample(RESAMPLE_FREQ).sum()
            
        df_feat, q70_thresh = make_wave_features(df_resampled, df_sched_raw, freq_td)
        
        # åŸºæº–æ—¥æ™‚ã®æ±ºå®š
        if TARGET_DATETIME:
            try:
                current_time = pd.to_datetime(TARGET_DATETIME)
                target_data_all = df_feat[df_feat.index <= current_time]
                target_data = target_data_all.iloc[-1:] if not target_data_all.empty else df_feat.iloc[-1:]
            except:
                target_data = df_feat.iloc[-1:]
        else:
            target_data = df_feat.iloc[-1:]
        current_time = target_data.index[0]
        
        # 4. æŒ‡æ¨™è¨ˆç®—ã¨æ¨è«–
        metrics = compute_personal_metrics(df_feat, freq_td, current_time)
        model, feature_cols, eval_metrics, df_model = train_predict_classifier(df_feat, ahead_steps)
        
        focus_prob = 0.0
        if model is not None:
            focus_prob = model.predict_proba(target_data[feature_cols])[0, 1]

        # ç¾åœ¨ã®1åˆ†ç²’åº¦ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³å–å¾—
        current_1min = df_1min[df_1min.index <= current_time]
        cur_1m = current_1min.iloc[-1] if not current_1min.empty else df_1min.iloc[-1]
        
        fatigue_band = cur_1m.get('fatigue_level_band', 'ä¸æ˜')
        fatigue_drift = cur_1m.get('fatigue_drift_60m', 0.0)
        drift_str = "è“„ç©ä¸­ â†—" if fatigue_drift > 0.05 else "å›å¾©å‚¾å‘ â†˜" if fatigue_drift < -0.05 else "æ¨ªã°ã„ â†’"
        
        la_band = cur_1m.get('low_arousal_band', 'ä¸æ˜')
        la_rise = cur_1m.get('low_arousal_rise_15m', 0.0)
        la_str = "ä¸Šæ˜‡ä¸­ âš ï¸" if la_rise > 0.5 else "å®‰å®š"

        # --- ç¾åœ¨ã®æ³¢ã®ä½ç›¸ã¨æ¬¡ãƒ”ãƒ¼ã‚¯æ¨è¨ˆ ---
        current_phase = target_data['phase_str'].values[0]
        avg_period = metrics['avg_wave_period']
        last_peak_time_val = target_data['last_peak_time'].values[0]
        if pd.notna(last_peak_time_val):
            last_peak_dt = pd.to_datetime(last_peak_time_val)
            mins_since_peak = (current_time - last_peak_dt).total_seconds() / 60
            next_peak_in = max(0, int(avg_period - mins_since_peak))
        else:
            next_peak_in = int(avg_period)

        # --- æ¬¡ã®Deep Workãƒãƒ£ãƒ³ã‚¹ç®—å‡º ---
        next_chance_text = "æœ¬æ—¥ã¯çµ‚äº†ã€ã¾ãŸã¯ç©ºãæ™‚é–“ãŒã‚ã‚Šã¾ã›ã‚“"
        if current_time.hour < 19:
            end_of_day = current_time.replace(hour=19, minute=0, second=0)
            future_mask = (df_feat.index > current_time) & (df_feat.index <= end_of_day) & (df_feat['has_schedule'] == 0)
            future_blank_times = df_feat[future_mask].index
            
            if not future_blank_times.empty:
                blank_blocks = (future_mask != future_mask.shift()).cumsum()[future_mask]
                longest_block_id = blank_blocks.value_counts().idxmax()
                best_block_times = future_blank_times[blank_blocks == longest_block_id]
                if len(best_block_times) > 0:
                    c_start = best_block_times[0]
                    c_end = best_block_times[-1] + freq_td
                    next_chance_text = f"{c_start.strftime('%H:%M')} â€“ {c_end.strftime('%H:%M')}"

        # --- ç”Ÿç”£æ€§ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ææ¡ˆåˆ¤å®š ---
        is_focus_low = focus_prob < 0.4
        action_text = "ç¾åœ¨ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã¯å®‰å®šã—ã¦ã„ã¾ã™ã€‚ã“ã®ã¾ã¾æ³¢ã«ä¹—ã£ã¦Deep Workã‚’é€²ã‚ã¾ã—ã‚‡ã†ã€‚"
        if la_band == 'é«˜' and is_focus_low:
            action_text = "é›†ä¸­åŠ›ãŒä½ä¸‹ã—ã€çœ æ°—ï¼ˆä½è¦šé†’ï¼‰ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚çŸ­ã„æ­©è¡Œã‚„è»½ã„ã‚¹ãƒˆãƒ¬ãƒƒãƒã§è„³ã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã—ã¾ã—ã‚‡ã†ã€‚"
        elif la_band == 'é«˜' and fatigue_band == 'é«˜':
            action_text = "ç–²åŠ´ã¨çœ æ°—ãŒãƒ”ãƒ¼ã‚¯ã«é”ã—ã¦ã„ã¾ã™ã€‚ç„¡ç†ãªä½œæ¥­ã¯æ§ãˆã€å®Œå…¨ãªä¼‘æ¯ã‚’å–ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚"
        elif la_band == 'é«˜' and fatigue_band == 'ä½':
            action_text = "ç–²åŠ´ã¯å°‘ãªã„ã§ã™ãŒã€å˜èª¿ã•ã‹ã‚‰çœ æ°—ãŒç”Ÿã˜ã¦ã„ã¾ã™ã€‚å°‘ã—ç«‹ã¡ä¸ŠãŒã£ã¦æ­©ããªã©ã€å§¿å‹¢ã‚’å¤‰ãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚"

    # ==========================================
    # UI æç”»
    # ==========================================
    st.markdown(f"<p style='text-align: right; color: gray;'>æœ€çµ‚æ›´æ–°: {current_time.strftime('%Y/%m/%d %H:%M')}</p>", unsafe_allow_html=True)
    
    tab_today, tab_weekly, tab_spec = st.tabs(["ğŸŒŠ Today (æ³¢ã¨æˆæœã®ç®¡ç†)", "ğŸ“Š Weekly Report", "ğŸ‘¤ My Spec (æ³¢ã®ç‰¹æ€§)"])

    # --- TAB 1: Today (æ„æ€æ±ºå®šæ”¯æ´UI) ---
    with tab_today:
        col_m1, col_m2, col_m3 = st.columns([1, 1, 1])
        with col_m1:
            remain_dw = max(0, metrics['target_dw_mins'] - metrics['today_dw_mins'])
            achieved_color = "ğŸŸ¢ ç›®æ¨™ã‚¯ãƒªã‚¢ï¼" if remain_dw == 0 else f"ç›®æ¨™ã¾ã§ã‚ã¨ {remain_dw} åˆ†"
            st.markdown(f"""
            <div class="kpi-card" style="border-top: 5px solid #0f172a; height: 100%;">
                <div class="kpi-title">ä»Šæ—¥ã®Deep Worké”æˆçŠ¶æ³</div>
                <div class="kpi-value-main">
                    {int(metrics['today_dw_mins'])} <span class="kpi-unit">/ {metrics['target_dw_mins']} åˆ†</span>
                </div>
                <div class="kpi-sub {'alert' if remain_dw > 60 else ''}">{achieved_color}</div>
            </div>
            """, unsafe_allow_html=True)
            
        with col_m2:
            phase_color = "#ef4444" if "ä¸‹é™" in current_phase else "#10b981" if "ä¸Šæ˜‡" in current_phase else "#64748b"
            st.markdown(f"""
            <div class="kpi-card" style="border-top: 5px solid #3b82f6; height: 100%;">
                <div class="kpi-title">ç¾åœ¨ã®é›†ä¸­æ³¢ãƒ•ã‚§ãƒ¼ã‚º</div>
                <div class="kpi-value-wave" style="color: {phase_color};">{current_phase}</div>
                <div class="kpi-sub" style="color:#64748b; font-weight:normal;">æ¬¡ã®é›†ä¸­ãƒ”ãƒ¼ã‚¯äºˆæƒ³: ç´„ <strong>{next_peak_in} åˆ†å¾Œ</strong></div>
            </div>
            """, unsafe_allow_html=True)
            
        with col_m3:
            prob_color = "#10b981" if focus_prob > 0.6 else "#f59e0b" if focus_prob > 0.4 else "#ef4444"
            st.markdown(f"""
            <div class="kpi-card" style="border-top: 5px solid #8b5cf6; height: 100%;">
                <div class="kpi-title">{PREDICT_AHEAD_MINS}åˆ†å¾Œã® é«˜é›†ä¸­æ³¢ å†çªå…¥ç¢ºç‡</div>
                <div class="kpi-value-main" style="color: {prob_color};">{focus_prob * 100:.1f} <span class="kpi-unit">%</span></div>
                <div class="kpi-sub" style="color:#64748b; font-weight:normal;">ä¸Šä½30%ã®ã‚¾ãƒ¼ãƒ³ã«åˆ°é”ã™ã‚‹ç¢ºç‡</div>
            </div>
            """, unsafe_allow_html=True)
            
        # ğŸ”‹ è¿½åŠ : ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ (ç–²åŠ´ãƒ»è¦šé†’)
        st.markdown("### ğŸ”‹ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ (ç–²åŠ´ãƒ»è¦šé†’)")
        col_c1, col_c2, col_c3 = st.columns([1, 1, 1.5])
        with col_c1:
            f_color = "#ef4444" if fatigue_band == 'é«˜' else "#10b981" if fatigue_band == 'ä½' else "#f59e0b"
            st.markdown(f"""
            <div class="kpi-card" style="border-top: 5px solid {f_color}; padding: 15px;">
                <div class="kpi-title" style="font-size:0.9rem;">ç¾åœ¨ã®ç–²åŠ´ãƒ¬ãƒ™ãƒ«</div>
                <div style="font-size:2rem; font-weight:bold; color:{f_color};">{fatigue_band}</div>
                <div style="font-size:0.9rem; color:#64748b;">ãƒˆãƒ¬ãƒ³ãƒ‰: {drift_str}</div>
            </div>
            """, unsafe_allow_html=True)
            
        with col_c2:
            la_color = "#ef4444" if la_band == 'é«˜' else "#10b981" if la_band == 'ä½' else "#f59e0b"
            st.markdown(f"""
            <div class="kpi-card" style="border-top: 5px solid {la_color}; padding: 15px;">
                <div class="kpi-title" style="font-size:0.9rem;">ç¾åœ¨ã®ä½è¦šé†’ (çœ æ°—)</div>
                <div style="font-size:2rem; font-weight:bold; color:{la_color};">{la_band}</div>
                <div style="font-size:0.9rem; color:#64748b;">çŠ¶æ…‹: {la_str}</div>
            </div>
            """, unsafe_allow_html=True)
            
        with col_c3:
            st.markdown(f"""
            <div class="chance-box" style="margin-bottom: 0; background-color: #f8fafc; border-left: 6px solid #3b82f6;">
                <div class="kpi-title" style="color: #1e293b; font-size:0.9rem;">ğŸ¤– AIã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ</div>
                <div style="font-size: 1.1rem; color: #334155; margin-top: 10px; font-weight: 500;">{action_text}</div>
            </div>
            """, unsafe_allow_html=True)

        st.markdown("<br>", unsafe_allow_html=True)
        col_s1, col_s2 = st.columns([1, 1.5])
        with col_s1:
            st.markdown(f"""
            <div style="display: flex; gap: 10px;">
                <div class="kpi-card" style="flex: 1; padding: 15px;">
                    <div class="kpi-title" style="font-size:0.85rem;">ç©ºç™½æ™‚é–“ã®é›†ä¸­ç‡</div>
                    <div style="font-size:1.8rem; font-weight:bold; color:#334155;">{metrics['today_dw_rate']:.1f} <span style="font-size:1rem;">%</span></div>
                </div>
                <div class="kpi-card" style="flex: 1; padding: 15px;">
                    <div class="kpi-title" style="font-size:0.85rem;">åˆ†æ–­ãƒ­ã‚¹(æ³¢ã®é “æŒ«)</div>
                    <div style="font-size:1.8rem; font-weight:bold; color:#334155;">{int(metrics['today_dw_loss'])} <span style="font-size:1rem;">åˆ†</span></div>
                </div>
            </div>
            """, unsafe_allow_html=True)
        with col_s2:
            st.markdown(f"""
            <div class="chance-box" style="margin-bottom: 0;">
                <div class="kpi-title" style="color: #047857;">ğŸ¯ æ¬¡ã®Deep Workãƒãƒ£ãƒ³ã‚¹æ </div>
                <div class="chance-time">{next_chance_text}</div>
                <div style="font-size: 0.95rem; color: #065f46; margin-top: 8px;">ã“ã®æ™‚é–“ã‚’æ­»å®ˆã—ã€æ³¢ã«ä¹—ã£ã¦é‡è¦ã‚¿ã‚¹ã‚¯ã‚’æ¶ˆåŒ–ã—ã¦ãã ã•ã„ã€‚</div>
            </div>
            """, unsafe_allow_html=True)

    # --- TAB 2: Weekly Report ---
    with tab_weekly:
        st.markdown("## ä»Šé€±ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³æŒ¯ã‚Šè¿”ã‚Š")
        
        past_7_days = current_time.date() - pd.Timedelta(days=7)
        past_14_days = current_time.date() - pd.Timedelta(days=14)
        
        df_this_week = df_feat[(df_feat['date'] > past_7_days) & (df_feat['date'] <= current_time.date())]
        df_last_week = df_feat[(df_feat['date'] > past_14_days) & (df_feat['date'] <= past_7_days)]
        
        tw_dw = df_this_week['deep_work'].sum() * (freq_td.total_seconds() / 60)
        lw_dw = df_last_week['deep_work'].sum() * (freq_td.total_seconds() / 60)
        diff_dw = tw_dw - lw_dw
        
        st.metric("ä»Šé€±ã®Deep Workåˆè¨ˆæ™‚é–“", f"{int(tw_dw)} åˆ†", f"{'+' if diff_dw>=0 else ''}{int(diff_dw)} åˆ† (å…ˆé€±æ¯”)")
        
        # è¿½åŠ : æ—¥åˆ¥ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ ã‚µãƒãƒªãƒ¼
        st.markdown("#### ğŸ“… æ—¥åˆ¥ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ãƒ»ã‚µãƒãƒªãƒ¼ (ç–²åŠ´ã¨å›å¾©)")
        df_daily_cond = summarize_daily_condition(df_1min)
        if not df_daily_cond.empty:
            st.dataframe(df_daily_cond, use_container_width=True)
        else:
            st.info("ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚µãƒãƒªãƒ¼ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")

        st.markdown("#### ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‘ãŸé»„é‡‘ãƒ‘ã‚¿ãƒ¼ãƒ³")
        
        df_feat_wd = df_feat[df_feat['dayofweek'] < 5].copy()
        if not df_feat_wd.empty and df_feat_wd['date'].nunique() >= 3:
            daily_stats = []
            for d, group in df_feat_wd.groupby('date'):
                am_group = group[group.index.hour < 12]
                pm_group = group[group.index.hour >= 12]
                
                dw_mins = group['deep_work'].sum() * (freq_td.total_seconds() / 60)
                am_dw_mins = am_group['deep_work'].sum() * (freq_td.total_seconds() / 60)
                am_meeting = am_group['is_meeting'].sum() * (freq_td.total_seconds() / 60)
                pm_blank = (pm_group['has_schedule'] == 0).sum() * (freq_td.total_seconds() / 60)
                steps = group['1åˆ†é–“æ­©æ•°'].sum() if '1åˆ†é–“æ­©æ•°' in group.columns else 0
                
                blank_mask = group['has_schedule'] == 0
                blank_blocks = blank_mask.groupby((blank_mask != blank_mask.shift()).cumsum()).sum()
                longest_blank = blank_blocks.max() * (freq_td.total_seconds() / 60) if not blank_blocks.empty else 0
                
                daily_stats.append({
                    'date': d, 'dw_mins': dw_mins, 'am_dw_mins': am_dw_mins,
                    'am_meeting': am_meeting, 'pm_blank': pm_blank,
                    'steps': steps, 'longest_blank': longest_blank
                })
                
            df_daily = pd.DataFrame(daily_stats)
            avg_dw_all = df_daily['dw_mins'].mean()
            
            if avg_dw_all > 0:
                patterns = []
                m_am = df_daily['am_meeting'].median()
                m_pm = df_daily['pm_blank'].median()
                mask1 = (df_daily['am_meeting'] >= m_am) & (df_daily['pm_blank'] >= m_pm) & (df_daily['am_meeting'] > 0)
                if mask1.sum() >= 1 and (~mask1).sum() >= 1:
                    avg_dw = df_daily[mask1]['dw_mins'].mean()
                    if avg_dw > avg_dw_all * 1.05:
                        patterns.append((avg_dw / avg_dw_all, "åˆå‰ä¸­ã«ä¼šè­°ã‚’å¯„ã›ã¦ã€åˆå¾Œã«ã¾ã¨ã¾ã£ãŸç©ºç™½ã‚’ä½œã£ãŸæ—¥"))
                        
                if df_daily['steps'].max() > 0:
                    m_steps = df_daily['steps'].median()
                    mask2 = df_daily['steps'] > m_steps
                    if mask2.sum() >= 1 and (~mask2).sum() >= 1:
                        avg_dw = df_daily[mask2]['dw_mins'].mean()
                        if avg_dw > avg_dw_all * 1.05:
                            patterns.append((avg_dw / avg_dw_all, "èº«ä½“ã‚’å‹•ã‹ã—æ´»å‹•é‡ï¼ˆæ­©æ•°ï¼‰ã‚’å¹³å‡ä»¥ä¸Šã«ç¢ºä¿ã—ãŸæ—¥"))
                            
                mask3 = df_daily['longest_blank'] >= 90
                if mask3.sum() >= 1 and (~mask3).sum() >= 1:
                    avg_dw = df_daily[mask3]['dw_mins'].mean()
                    if avg_dw > avg_dw_all * 1.05:
                        patterns.append((avg_dw / avg_dw_all, "1æ—¥ã®ã©ã“ã‹ã§ã€Œ90åˆ†ä»¥ä¸Šã®é€£ç¶šã—ãŸç©ºç™½æ ã€ã‚’æ­»å®ˆã—ãŸæ—¥"))
                        
                mask4 = df_daily['am_dw_mins'] > 0
                if mask4.sum() >= 1 and (~mask4).sum() >= 1:
                    avg_dw = df_daily[mask4]['dw_mins'].mean()
                    if avg_dw > avg_dw_all * 1.05:
                        patterns.append((avg_dw / avg_dw_all, "åˆå‰ä¸­ã®ã†ã¡ã«1å›ã§ã‚‚Deep Workã®æ³¢ã«ä¹—ã‚ŒãŸæ—¥"))
                        
                patterns.sort(key=lambda x: x[0], reverse=True)
                top_patterns = patterns[:3]
                
                if top_patterns:
                    icons = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"]
                    for i, (ratio, text) in enumerate(top_patterns):
                        st.info(f"{icons[i]} **ã€Œ{text}ã€** ã¯ã€æ³¢ãŒé€”åˆ‡ã‚ŒãšDeep Workæ™‚é–“ãŒå¹³å‡ã® **{ratio:.1f}å€** ã«ãªã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")
                else:
                    st.info("ğŸ’¡ å®‰å®šã—ãŸæˆæœã‚’å‡ºã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ãƒ‡ãƒ¼ã‚¿ãŒè“„ç©ã•ã‚Œã‚‹ã¨ã€ã‚ãªãŸå°‚ç”¨ã®ã€Œé»„é‡‘ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
        
        st.markdown("---")
        st.markdown("#### ğŸŒŠ ä»Šé€±ã®é›†ä¸­æ³¢å½¢ (ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ«ã‚°ãƒ©ãƒ•)")
        st.caption("â€» é’ã„ç·šãŒå¹³æ»‘åŒ–ã•ã‚ŒãŸé›†ä¸­ã®ã€Œæ³¢ã€ã‚’è¡¨ã—ã€èµ¤ã„ç‚¹ãŒAIãŒæ¤œå‡ºã—ãŸã€Œæ³¢ã®ãƒ”ãƒ¼ã‚¯ã€ã§ã™ã€‚ã‚°ãƒ¬ãƒ¼ã®ç‚¹ç·šã‚ˆã‚Šä¸Šã®é’ã„é¢ãŒã€Œé«˜é›†ä¸­ã‚¾ãƒ¼ãƒ³ï¼ˆDeep Workã®å€™è£œï¼‰ã€ã§ã™ã€‚æ³¢ã®å‘¨æœŸæ€§ï¼ˆãƒªã‚ºãƒ ï¼‰ãŒè¦–è¦šçš„ã«ç¢ºèªã§ãã¾ã™ã€‚")
        
        week_dates = df_this_week['date'].unique()
        if len(week_dates) > 0:
            for i in range(0, len(week_dates), 2):
                cols = st.columns(2)
                for j in range(2):
                    if i + j < len(week_dates):
                        t_date = week_dates[i+j]
                        with cols[j]:
                            df_day = df_this_week[df_this_week['date'] == t_date].copy()
                            df_day = df_day[(df_day.index.hour >= time_range[0]) & (df_day.index.hour <= time_range[1])]
                            
                            if not df_day.empty and not df_day['focus_smooth'].isna().all():
                                fig_d = go.Figure()
                                q70_val = q70_thresh 
                                fig_d.add_trace(go.Scatter(x=df_day.index, y=[q70_val]*len(df_day), mode='lines', line=dict(color='gray', width=1, dash='dash'), name='é«˜é›†ä¸­ãƒ©ã‚¤ãƒ³', hoverinfo='skip'))
                                y_up = np.where(df_day['focus_smooth'] >= q70_val, df_day['focus_smooth'], q70_val)
                                fig_d.add_trace(go.Scatter(x=df_day.index, y=y_up, fill='tonexty', fillcolor='rgba(59, 130, 246, 0.3)', mode='lines', line=dict(width=0), hoverinfo='skip', showlegend=False))
                                fig_d.add_trace(go.Scatter(x=df_day.index, y=[q70_val]*len(df_day), fill='tonexty', fillcolor='rgba(0,0,0,0)', mode='lines', line=dict(width=0), hoverinfo='skip', showlegend=False))
                                fig_d.add_trace(go.Scatter(x=df_day.index, y=df_day['focus_smooth'], mode='lines', line=dict(color='#3b82f6', width=2), name='é›†ä¸­æ³¢', hovertemplate="%{x|%H:%M}<br>å¼·åº¦: %{y:.1f}<extra></extra>"))
                                peaks_day = df_day[df_day['is_peak'] == 1]
                                if not peaks_day.empty:
                                    fig_d.add_trace(go.Scatter(x=peaks_day.index, y=peaks_day['focus_smooth'], mode='markers', marker=dict(color='#ef4444', size=6, symbol='circle'), name='ãƒ”ãƒ¼ã‚¯', hovertemplate="%{x|%H:%M}<br>ãƒ”ãƒ¼ã‚¯<extra></extra>"))
                                dow_str = ['æœˆ','ç«','æ°´','æœ¨','é‡‘','åœŸ','æ—¥'][t_date.weekday()]
                                fig_d.update_layout(title=f"{t_date.strftime('%m/%d')} ({dow_str})", height=250, hovermode="x unified", plot_bgcolor='rgba(0,0,0,0)', margin=dict(l=20, r=20, t=30, b=20), showlegend=False)
                                fig_d.update_xaxes(showgrid=True, gridcolor='lightgray')
                                y_min = df_day['focus_smooth'].min()
                                y_max = df_day['focus_smooth'].max()
                                amp = y_max - y_min if y_max - y_min > 0 else 10
                                fig_d.update_yaxes(showgrid=True, gridcolor='lightgray', title="é›†ä¸­å¼·åº¦", range=[max(0, y_min - amp*0.2), y_max + amp*0.2])
                                st.plotly_chart(fig_d, use_container_width=True)
                            else:
                                st.markdown(f"**{t_date.strftime('%m/%d')} ({['æœˆ','ç«','æ°´','æœ¨','é‡‘','åœŸ','æ—¥'][t_date.weekday()]})**")
                                st.info("æŒ‡å®šã•ã‚ŒãŸæ™‚é–“å¸¯ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    # --- TAB 3: My Spec ---
    with tab_spec:
        st.markdown("## ğŸ‘¤ ã‚ãªãŸã®ã€Œé›†ä¸­ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã€æ”»ç•¥æ³•")
        st.write("éå»ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’æ³¢å½¢è§£æã—ã€ã‚ãªãŸå›ºæœ‰ã®é›†ä¸­ãƒªã‚ºãƒ ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")
        
        best_hour = df_feat.groupby('hour')['deep_work'].sum().idxmax()
        
        c_spec1, c_spec2, c_spec3 = st.columns(3)
        c_spec1.metric("â± å¹³å‡é›†ä¸­æ³¢ å‘¨æœŸ", f"{int(metrics['avg_wave_period'])} åˆ†", "æ³¢ãŒè¨ªã‚Œã‚‹é–“éš”")
        c_spec2.metric("ğŸ¯ æœ€é©é›†ä¸­æ™‚é–“å¸¯", f"{best_hour}:00 å°", "æ³¢ãŒæœ€å¤§åŒ–ã™ã‚‹æ™‚é–“")
        c_spec3.metric("ğŸ“ˆ æ³¢ã®å¹³å‡æŒ¯å¹…", f"{metrics['avg_wave_amplitude']:.1f} pt", "é›†ä¸­ã®æ·±ã•ã®æŒ‡æ¨™")
        
        st.markdown("""
        <div style="background-color: #f8fafc; padding: 20px; border-radius: 8px; border-left: 4px solid #3b82f6; margin-top: 20px;">
            <h4>ğŸ“ AIã‹ã‚‰ã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«ã‚³ãƒ¡ãƒ³ãƒˆ</h4>
            <ul style="font-size: 1.1rem; color: #334155; line-height: 1.6;">
                <li>ã‚ãªãŸã®é›†ä¸­ã¯<strong>ç´„ {0} åˆ†å‘¨æœŸ</strong>ã®æ³¢ã‚’æã„ã¦ã„ã¾ã™ã€‚ç–²ã‚ŒãŸæ™‚ã¯ç„¡ç†ã‚’ã›ãšã€æ¬¡ã®æ³¢ãŒæ¥ã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«åˆã‚ã›ã¦ä½œæ¥­ã‚’å†é–‹ã™ã‚‹ã®ãŒåŠ¹ç‡çš„ã§ã™ã€‚</li>
                <li><strong>{1}æ™‚å°</strong>ã«æ³¢ã®æŒ¯å¹…ãŒæœ€å¤§åŒ–ã—ã€æ¥µã‚ã¦æ·±ã„é›†ä¸­çŠ¶æ…‹ã«å…¥ã‚Šã‚„ã™ããªã‚Šã¾ã™ã€‚ã“ã®æ™‚é–“å¸¯ã¯æ­»å®ˆã—ã¦ãã ã•ã„ã€‚</li>
                <li>äºˆå®šã®åˆé–“ãŒçŸ­ã™ãã‚‹ã¨ã€æ³¢ãŒä¸Šæ˜‡ã—ãã‚‹å‰ã«åˆ†æ–­ã•ã‚Œã¦ã—ã¾ã†ã€Œåˆ†æ–­ãƒ­ã‚¹ã€ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚ä¼šè­°ã¯å›ºã‚ã¦é…ç½®ã—ã¾ã—ã‚‡ã†ã€‚</li>
            </ul>
        </div>
        """.format(int(metrics['avg_wave_period']), best_hour), unsafe_allow_html=True)

    # --- é–‹ç™ºè€…å‘ã‘ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
    with st.expander("ğŸ›  é–‹ç™ºè€…å‘ã‘æƒ…å ± (ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ç‰¹å¾´é‡)"):
        st.markdown("### ğŸ”¬ æ–°è¦ãƒ¬ã‚¤ãƒ¤ãƒ¼ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©")
        st.write("- **Fatigue Score (ç–²åŠ´)**: 0.6 * RMSSD_SCORE_NEW + 0.4 * TP_SCORE_NEW (10åˆ† EWMA)")
        st.write("- **Low Arousal (ä½è¦šé†’)**: PR_SCORE_NEW ã®5åˆ†çª“å‚¾ãï¼ˆä½ä¸‹æ–¹å‘ã®ã¿ï¼‰ã‚’æ¸›è¡°ç©åˆ† (alpha=0.95, eps=0.02)")
        
        # ç–²åŠ´ã¨ä½è¦šé†’ã®ãƒ—ãƒ­ãƒƒãƒˆ (å½“æ—¥)
        today_1min = df_1min[df_1min.index.date == current_time.date()]
        if not today_1min.empty:
            fig_cond = go.Figure()
            fig_cond.add_trace(go.Scatter(x=today_1min.index, y=today_1min['fatigue_smooth'], name='ç–²åŠ´(Smooth)', line=dict(color='#ef4444')))
            if 'low_arousal' in today_1min.columns:
                # è¦–èªæ€§å‘ä¸Šã®ãŸã‚ã‚¹ã‚±ãƒ¼ãƒ«ã‚’èª¿æ•´ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆ
                scaled_la = today_1min['low_arousal'] * (today_1min['fatigue_smooth'].max() / (today_1min['low_arousal'].max() + 0.1))
                fig_cond.add_trace(go.Scatter(x=today_1min.index, y=scaled_la, name='ä½è¦šé†’(ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¸ˆ)', line=dict(color='#8b5cf6')))
            fig_cond.update_layout(title="æœ¬æ—¥ã®ç–²åŠ´ãƒ»ä½è¦šé†’ æ¨ç§»", height=300, margin=dict(l=20, r=20, t=30, b=20), hovermode="x unified")
            st.plotly_chart(fig_cond, use_container_width=True)

        st.markdown("### ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™ (åˆ†é¡ãƒ¢ãƒ‡ãƒ«)")
        col_ev1, col_ev2, col_ev3 = st.columns(3)
        if eval_metrics:
            col_ev1.metric("ROC-AUC", f"{eval_metrics.get('ROC-AUC', 0):.3f}")
            col_ev2.metric("PR-AUC", f"{eval_metrics.get('PR-AUC', 0):.3f}")
            col_ev3.metric("F1 Score", f"{eval_metrics.get('F1 Score', 0):.3f}")
        else:
            st.warning("è©•ä¾¡ã«å¿…è¦ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆæ­£ä¾‹ãƒ»è² ä¾‹ï¼‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
            
        st.markdown("### ç›´è¿‘äºˆæ¸¬ã®æ ¹æ‹  (SHAP)")
        if model is not None:
            explainer = shap.TreeExplainer(model)
            shap_values = explainer(target_data[feature_cols])
            fig_shap, ax_shap = plt.subplots(figsize=(8, 4))
            if len(shap_values.shape) == 3:
                shap.plots.waterfall(shap_values[0, :, 1], show=False)
            else:
                shap.plots.waterfall(shap_values[0], show=False)
            st.pyplot(fig_shap)